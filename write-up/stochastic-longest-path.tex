% !TeX document-id = {54177b55-cdde-488b-90fe-107922d59049}
\documentclass[12pt]{article}

\usepackage{a4} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[]{xcolor}
\usepackage{graphicx}
\usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=hotpink]{hyperref}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{caption}
\usepackage[british]{babel}
\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage{epstopdf}
\usepackage{mathtools} % for :=
\usepackage{subfig}
\usepackage[most, minted]{tcolorbox}
\usepackage{mdwlist}
\tcbuselibrary{listings}

\newtcblisting{myminted}{%
	listing engine=minted,
	minted language=python,
	listing only,
	breakable,
	enhanced,
	minted options = {
		linenos, 
		breaklines=true, 
		breakanywhere, 
		fontsize=\footnotesize, 
		numbersep=2mm,
		tabsize=2
	},
	overlay={%
		\begin{tcbclipinterior}
			\fill[gray!25] (frame.south west) rectangle ([xshift=4mm]frame.north west);
		\end{tcbclipinterior}
	}   
}
\BeforeBeginEnvironment{minted}{\begin{tcolorbox}[breakable, enhanced]}%
	\AfterEndEnvironment{minted}{\end{tcolorbox}}%


\graphicspath{{images/}}

\title{Approximating the makespan distribution of stochastic schedules} % Think of a better title...
\author{Thomas McSweeney%
	\thanks{%
		School of Mathematics,
		University of Manchester,
		Manchester, M13 9PL, England
		(\texttt{thomas.mcsweeney@postgrad.manchester.ac.uk}).
	}
}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}
\def\nbyn{n \times n}
\def\mbyn{m \times n}
\def\l{\lambda}
\def\norm#1{\|#1\|}      
\def\normi#1{\|#1\|_1}
\def\normo#1{\|#1\|_{\infty}}
\def\Chat{\widehat{C}}
\def\e{eigenvalue}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% \DeclareMathOperator{\diag}{diag}   % Requires amsmath.
\def\diag{\mathop{\mathrm{diag}}}     % If not using amsmath.
\def\trace{\mathop{\mathrm{trace}}}   % If not using amsmath.

\def\At{\widetilde{A}}
\def\normt#1{\|#1\|_2}

% Set up lemma environment and its numbering.
\newtheorem{lemma}{Lemma}[section]

\def\proof{{\bf Proof}. \ignorespaces}
\def\qedsymbol{\vbox{\hrule\hbox{%
			\vrule height1.3ex\hskip0.8ex\vrule}\hrule}}
\def\endproof{\qquad\qedsymbol\medskip\par}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}

\allowdisplaybreaks[1]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% For fine-tuning spacing in \sqrt etc=.  From \cite[p.~155]{knut99}.
% In math mode, @ will act as a macro that adds 1 unit of space.
% By comparison, \, skips 3mu.

\mathcode`@="8000 % Make @ behave as per catcode 13 (active).  TeXbook p. 155.
{\catcode`\@=\active\gdef@{\mkern1mu}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcounter{mylineno}
\makeatletter
\let\oldtabcr\@tabcr
\def\nonumberbreak{\oldtabcr\hspace{3.5pt}}
\def\mynewline{\refstepcounter{mylineno}%
	\llap{\footnotesize\arabic{mylineno}\hspace{5pt}}%
}
\def\lineref#1{\footnotesize\ref{#1}}
% Next macro adapted from latex.ltx
\gdef\@tabcr{\@stopline \@ifstar{\penalty%
		\@M \@xtabcr}\@xtabcr\mynewline}
\def\myvspace#1{\oldtabcr[#1]\mynewline}
\newenvironment{code}{%
	% Swap `:' and `colon'...
	\mathcode`\:="603A  % TeXbook pp 134, 154, 359 (top)
	% For original colon     \mathcode`\:="303A  % TeXbook p 344
	\def\colon{\mathchar"303A}
	\setcounter{mylineno}{0}
	\par
	\upshape
	\begin{list} % To give indentation
		{} {\leftmargin = 1cm}
		\item[]
		\begin{tabbing}
			
			% Default tab stops
			\hspace*{.3in} \= \hspace*{.3in} \=
			\hspace*{.3in} \= \hspace*{.3in} \= \kill
			\mynewline
		}{\end{tabbing}\end{list}}
\makeatother


\addto\captionsbritish{	\renewcommand{\bibname}%
	{References}%TODO: make sure reference style is consistent.
}

\definecolor{hotpink}{rgb}{0.9,0,0.5}

\begin{document}
	\maketitle 	


\section{Introduction}
\label{sect.intro}

% Questions for Neil: longest path or makespan throughout?

For any optimization problem, we obviously need to be able to evaluate how good any given solution is with regards to the optimization criteria in order to find an optimal, or otherwise acceptable, solution. The scheduling problems we consider here are clearly no exception: we want to know how good a computed schedule is, whether there are other schedules which are better, and so on. Evaluating the makespan of a given schedule would appear to be a straightforward problem---and so it is, when the computation and communication costs are static. But if costs are {\em stochastic} then this may no longer be the case.

Now, as long as it specifies the execution order of tasks on processors, any schedule $\pi$ for an application with task DAG $G$ can be represented by a {\em schedule graph} $G_{\pi}$ such that the longest path of $G_{\pi}$ is equal to the makespan of $\pi$: $G_\pi$ contains all the same vertices and edges as $G$, plus additional zero-weight {\em disjunctive} edges that indicate the execution order of the tasks on their chosen processors; the other weights of $G_\pi$ are induced by the processor selections of $\pi$. There's some flexibility in how we add the disjunctive edges; the most straightforward way to do it is to simply add an edge between a task $t_i$ and the task $t_h$ which is executed immediately before $t_i$ on its chosen processor if an edge does not already exist between the two.  
% We can interpret the entire scheduling problem as a question of how to add disjunctive edges such that the longest path is minimized...

For example, consider the schedule $\pi$ from Figure X and the graph $G$ in Figure Y. We can construct the associated graph $G_\pi$ as shown in Figure Z. From now, we use the notations $\pi_i$ and $\pi_{ik}$ to represent the computation cost of task $t_i$ and the communication cost between tasks $t_i$ and $t_k$ under the schedule $\pi$, respectively. Assuming, without loss of generality, that there is only one entry task $t_1$ and one exit task $t_n$, to compute the longest path through $G_\pi$---and therefore the makespan of $\pi$---we compute a sequence of numbers $L_i$ defined by $L_1 = \pi_1$ and
\begin{align}
  \label{eq.Li}
  L_i = \pi_i + \max_{h \in P_i}\{ \pi_{hi} + L_h\}
\end{align}
for all other $i = 2, \dots, n$. The longest path of $G_\pi$ is then given by $L_n$. In the example above, we have... so we see that $L_n$ is indeed equal to the schedule makespan. Computing the longest path using \eqref{eq.Li} is an $O(n + e) \approx O(n^2)$ operation, which depending on the size of the DAG may be expensive but is at least polynomial. (Of course, we could work backward through the DAG by setting $L_n = \pi_n$ and doing the maximization over the set of task children in \eqref{eq.Li} instead; the makespan would then be given by $L_1$ but the procedure is otherwise equivalent.)

Unfortunately, in practice, schedule costs are almost never known precisely before runtime. Typically, the best we can do is estimate the probability distribution that we believe they follow---i.e., we model the costs as random variables (RVs)---based either on theoretical results or a relevant body of data. But if costs are RVs rather than fixed scalars, it is obviously impossible to specify the precise time at which each task should begin execution so at this point we need to redefine what we mean by a schedule: here, we assume that a schedule $\pi$ is a mapping from tasks to processors that specifies only which tasks each processor should execute and in what order; the processor then executes the next scheduled task as soon as it is able. Conceptually, we can view this as a processor being assigned an ordered queue of tasks before runtime and only being allowed to pop the task currently at the head of the queue. 

This definition means that even though costs are stochastic, the disjunctive graph $G_\pi$ has the same topology as it would in the static case. However, since all costs are RVs, the longest path is also now an RV. Unfortunately, it is unclear how we should go about computing its distribution. Fundamentally, the problem is that even if all of the graph weights are independent of one another, path lengths typically aren't because of common nodes and edges. So if we attempt to apply \eqref{eq.Li} we soon run into difficulty because computing the maximum of a set of dependent RVs is intractable, with very rare exceptions. Furthermore, this presupposes that all individual cost distributions (and summations thereof) are fully known, which is rarely true in practice. Formalizing this intuitive difficulty, Hagstrom proved that computing the longest path distribution of a stochastic graph, or even just its expected value, is a $\#P$-complete problem when all weights are discrete RVs \cite{hag88}, and there is little reason to assume it is any easier in the continuous case.      

Given the difficulty of the problem, bounds or heuristic approximations for the longest path distribution---and therefore the schedule makespan distribution---are typically needed instead. In this chapter, we give a brief overview of various methods that have been employed for this purpose, with a particular focus on a family of efficient heuristics which are likely the most practical approach in the context of stochastic scheduling. Although useful on its own merits, in the context of this research this chapter functions as a bridge between earlier chapters which focus on computing schedules when costs are assumed to be known exactly and the later chapters in which the aim is to compute a schedule that is robust to the effects of uncertain cost estimates. We will see that many of the techniques discussed here underlie both existing stochastic scheduling heuristics and the new heuristic that we propose in the next chapter. This chapter is intended primarily as an literature review so there is relatively little new research, although we do take an extended look at a problem that has rarely been addressed before: how do we quickly update a longest path estimate---i.e., an estimated schedule makespan---as realizations become apparent at runtime? 

The problem of computing the distribution of the longest path through a DAG with stochastic weights was first studied in the context of {\em program evaluation review technique} (PERT) network analysis \cite{mal59}. Since a PERT network is essentially just what we have referred to here as a schedule graph, the longest path also typically represents an overall finish time---i.e., the makespan---and nodes tasks that must be completed. However, the stochastic longest path problem has also been studied in more dissimilar research areas such as digital circuit design \cite{bla08}, so in this chapter we typically use the more general {\em longest path} rather than {\em makespan}.  
% better reference for digital circuit design? 

\section{Bounds}
\label{sect.bounds}

Although computing the longest path distribution exactly is usually impossible, bounds on various quantities of interest may be computed much more cheaply. Depending of course on the context, these may be tight enough to be useful.

Some of the oldest results are concerned with the expected value. In particular, as we have already seen in previous chapters, a lower bound which dates back to the earliest days of PERT analysis can be computed in $O(n^2)$ operations by replacing all weight RVs with their expected value and proceeding as in \eqref{eq.Li}---i.e., define $u_1 = \E[\pi_1]$ and
\begin{align}
  \label{eq.ui}
  u_i = \E[\pi_i] + \max_{h \in P_i}\{ \E[\pi_{hi}] + u_h\}
\end{align}
for all other $i = 2, \dots, n$, then we have $u_i \leq \E[L_i]$ and in particular $u_n \leq \E[L_n]$. We will refer to this as the {\em critical path method} (CPM) bound. Furthermore, we also saw in the previous chapter that a tighter bound can be found through Fulkerson's \cite{ful62} alternative method, which was extended to continuous weights by Clingen \cite{cli64} and later improved by Elmaghraby \cite{elm67}. Although this approach as generalized by Robillard and Trahan \cite{rob76} can tighten the lower bound almost arbitrarily, the computational cost of even Fulkerson's bound can be prohibitive in some cases, as suggested by our experience in the previous chapter.    
% cpm bound since that was the context in which...

All of those methods provide only lower bounds for the expected value. However, an upper bound arises naturally from Dodin's method for bounding the distribution function (see below). If all node and edge weights are normally distributed, then Kamburowski \cite{kam85} was able to prove both lower and upper bounds on the expected value. However, his bounds---although exact when costs are normal---are conceptually very similar to a class of heuristics discussed in the following section, so will be described in more detail there. Kamburowski also provided bounds on the variance when all weights are normal. These are the only formal bounds on moments higher than the first that we are aware of, although he was unable to prove the upper and the lower is very loose.

More so than the expected value, we may be interested in bounds on the cdf of the distribution. Here, by a bound we mean...


Now, while bounds on the distribution itself have been proven---for example, Kleindorfer gives both upper and lower bounds \cite{kle71}, the first of which was improved on by Dodin \cite{dod85}---these are typically based on graph reductions and fairly expensive, perhaps impractically so in the context of a scheduling heuristic, which is where our interest ultimately lies.
% Complexity results/more detail?
% TODO: the best review of these results is probably by Ludwig (2001), who empirically compares the existing bounds and improves them...
% the tail distribution
% Concentration inequality...
% More discussion. Spelde's heuristic bound.
% Can be done in polynomial time but still slower than methods based on the CLT.


Rather than a formal bound, in many cases it may be more useful to simply approximate the longest path distribution. To that end, many heuristic methods have been proposed. We focus in this chapter largely on the family of heuristics described in the following section, although alternative methods are briefly discussed in Section \ref{sect.other_methods}.

% One approach that might be useful is to consider extreme value theory... The problem is that it isn't clear how to characterize the distribution. Paper by Berman (and other one) seems to suggest 


\section{Heuristics}
\label{sect.normality}

Fundamentally, the longest path is computed through a series of summations and maximizations of the cost RVs. By the Central Limit Theorem, sums of random variables are asymptotically normally distributed so if we assume that the effect of the maximizations is minor, then the longest path distribution is likely to be approximately normal, $L_n \approx N(\mu_n, \sigma_n)$. Indeed, this has often been observed empirically, even when all costs follow very different distributions \cite{can10}. If we assume further that all RVs can be characterized by their mean and variance (i.e., effectively that they are also normal), then sums can be computed though the well-known rule for summing two normal RVs $\epsilon \sim N(\mu_\epsilon, \sigma_\epsilon^2)$ and $\eta \sim N(\mu_\eta, \sigma_\eta^2)$,
\begin{align}
\label{eq.sum_moments}
\epsilon + \eta \sim N \big(\mu_\epsilon + \mu_\eta, \sigma_\epsilon^2 + \sigma_\eta^2 + 2 \rho_{\epsilon\eta}\sigma_\epsilon \sigma_\eta \big), 
\end{align}
where $\rho_{\epsilon\eta}$ is the linear correlation coefficient between the two distributions. Formulae for the first two moments of the maximization of two normal RVs---which is not itself normal---are less well-known but were first provided by Clark in the early 1960s \cite{cla61}. Let 
\begin{align*}
\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \quad \text{and} \quad \Phi(x) = \int_{-\infty}^{x} \phi(t) dt
\end{align*}
be the unit normal probability density function and cumulative probability function, respectively, and define 
\begin{align}
  \label{eq.alpha_beta}
\alpha = \sqrt{\sigma_\epsilon^2 + \sigma_\eta^2 - 2 \rho_{\epsilon\eta}\sigma_\epsilon \sigma_\eta} \quad \text{and} \quad \beta = \frac{\mu_\epsilon - \mu_\eta}{\alpha}. 
\end{align}
Then the first two moments $\mu_{\max}$ and $\sigma_{\max}$ of $\max(\epsilon, \eta)$ are given by
\begin{align}
\mu_{\max} &= \mu_\epsilon \Phi(\beta) + \mu_\eta \Phi(-\beta) + \alpha \phi(\beta), \label{eq.clark_max_mu}\\
\sigma_{\max}^2 &= (\mu_\epsilon^2 + \sigma_\epsilon^2) \Phi(\beta) + (\mu_\eta^2 + \sigma_\eta^2) \Phi(-\beta) \label{eq.clark_max_sigma}\\
&+ (\mu_\epsilon + \mu_\eta)\alpha\phi(\beta) -\mu_{\max}^2 \nonumber.
\end{align}
Using \eqref{eq.sum_moments} for summations, and \eqref{eq.clark_max_mu} and \eqref{eq.clark_max_sigma} for maximizations, we can now move through the DAG and compute approximations $\mu_n$ and $\sigma_n$ (or $\mu_1$ and $\sigma_1$ if working backward) of the first two moments of the longest path distribution in a manner similar to \eqref{eq.Li}.

This method appears to have first been proposed for estimating the completion time of PERT networks by Sculli \cite{scu83}, although there he assumed that all of the correlation coefficients $\rho_{\epsilon \eta}$ in \eqref{eq.alpha_beta} were zero (see next section). While there are obviously no guarantees, the moment estimates obtained using Sculli's method tend to be fairly good \cite{kam85}, with performance improving as the cost distributions move closer to normality and the number of nodes in the graph increases, as we might expect. Furthermore, Sculli's method is typically much faster than the alternatives \cite{can16}. 

\subsection{Including correlations}
\label{subsect.correlation_aware}

Sculli assumed that all correlations were zero, which is rarely the case for real graphs since common ancestors make the longest path at two nodes dependent, even if all costs themselves are independent. Computing the correlation coefficients efficiently is tricky. However, Canon and Jeannot \cite{can16} proposed two different heuristics which alternatively prioritize precision and speed. The first is a dynamic programming algorithm called Cordyn which recursively computes the correlations using formulae derived in Clark's original paper for the correlation coefficients between any normal RV $\tau$ and a summation or maximization of normal RVs $\epsilon$ and $\eta$, 
\begin{align*}
  \rho_{\tau, \, \text{sum}(\epsilon, \eta)} &= \frac{\sigma_\epsilon \rho_{\tau \epsilon} + \sigma_\eta \rho_{\tau \eta} }{\sigma_{\text{sum}}} \quad \text{and} \quad
\rho_{\tau, \max(\epsilon, \eta)} = \frac{\sigma_\epsilon \rho_{\tau \epsilon} \Phi(\beta) + \sigma_\eta \rho_{\tau \eta} \Phi(-\beta)}{\sigma_{\max}}.
\end{align*} 
Cordyn has time complexity $O(ne) \approx O(n^3)$, so is more expensive than Sculli's method, which is quadratic in $n$, however numerical experiments by Canon and Jeannot suggest that it is almost always more accurate. 
% something about being competitive with reduction based methods?

In an effort to marry the speed of Sculli's method and the accuracy of Cordyn, Canon and Jeannot also proposed an alternative heuristic called CorLCA. The main idea is to construct a simplified version of the DAG called a {\em correlation tree} that has all the same nodes as the original but only retains a subset of the edges. In particular, where multiple edges are incident to a node---i.e., a maximization must be performed---only the edge which contributes most to the maximization is retained in the correlation tree. The motivation here is that the correlation coefficient between any two longest path estimates $L_i$ and $L_k$ can be efficiently approximated by finding the {\em lowest common ancestor} (LCA) $t_{a}$ of the corresponding nodes $t_i$ and $t_k$ in the correlation tree: since $L_i \approx L_a + \eta$ and $L_k \approx L_a + \epsilon$ where $\eta$ and $\epsilon$ are independent RVs representing the sums of the costs along the paths between $t_a$ and $t_i$ (resp. $t_a$ and $t_k$) in the correlation tree, we have
\begin{align*}
  \rho_{L_i, L_k} \approx \frac{\sigma_{L_a}^2}{\sigma_{L_i}\sigma_{L_k}}. % Not technically correct---introduce C?
  \end{align*}
For every edge, we need to do a lowest common ancestor query, so the time complexity of CorLCA depends to a large extent on the cost of these queries. Although they do not present a method, based on similar results in the literature, Canon and Jeannot hypothesize this can be done in $O(1)$ operations, giving an overall time complexity $O(e) \approx O(n^2)$ for the entire algorithm. At any rate, an extensive numerical comparison of several heuristic methods for approximating the longest path distribution by the original authors suggested that CorLCA is more efficient than Cordyn with only a relatively small reduction in accuracy \cite{can16}. It should however also be noted that it can do badly when longest path length estimates at two or more nodes with a common child are similar since only one of the respective edges to the child will be retained in the correlation tree.   


Another method for estimating the longest path distribution that approximates correlations in a similar manner comes from the field of digital circuit design. In the so-called {\em canonical model} \cite{vis06,zha06}, all RVs are expressed as the sum of their expected value and a weighted sum of standard normal distributions that characterize the variance, 
\begin{align*}
\eta = \mu + \sum_i v_i \delta_i,
\end{align*}  
where all $\delta_i \sim N(0, 1)$ and are independent of one another. The advantage of this is that evaluating summations and maximizations becomes much more straightforward. Let $\eta = \mu_\eta + \sum_i v_{\eta, i} \delta_i$ and $\epsilon = \mu_\epsilon + \sum_i v_{\epsilon, i} \delta_i$. Then 
\begin{align*}
\omega = \eta + \epsilon = (\mu_\eta + \mu_\epsilon) + \sum_i (v_{\eta, i} + v_{\epsilon, i}) \delta_i.
\end{align*}
Suppose now that $\omega = \max(\eta, \epsilon)$. Let $\alpha$ and $\beta$ be defined as in \eqref{eq.alpha_beta}, and $\Phi(x) = \int_{-\infty}^{x} \phi(t) dt$ be the standard normal cdf. Note that computing $\beta$ requires the linear correlation coefficient $\rho_{\eta\epsilon}$ which can be efficiently calculated as:
\begin{align*}
\rho_{\eta\epsilon} = \frac{\sum_i v_{\eta, i} v_{\epsilon, i}}{\sqrt{\sum_i v_{\eta, i}^2} \cdot \sqrt{\sum_i v_{\epsilon, i}^2} }.
\end{align*}
By definition, $\P[\eta > \epsilon] = \Phi(\beta)$ and we can therefore approximate $\omega$ by 
\begin{align*}
\hat{\omega} &= \Phi(\beta)\eta + \Phi(-\beta) \\
&= \Phi(\beta) \mu_\epsilon + \Phi(-\beta) \mu_\epsilon + \sum_i \big( \Phi(\beta) v_{\eta, i} + \Phi(-\beta) v_{\epsilon, i} \big) \delta_i.
\end{align*}
This is both similar and in some sense contrary to the Clark equation approach, in that the latter precisely computes the first two moments of the maximization of two normal RVs, whereas the canonical method approximates the distribution of the maximization of any two RVs using linear combinations of normal RVs. In their empirical comparison, Canon and Jeannot found that the canonical method tended to fall between Sculli's method and CorLCA in terms of both speed and approximation quality \cite{can16}. 


\subsection{Kamburowski's bounds}
\label{subsect.kamburowski}

When all costs are independent Gaussian RVs, Kamburowski was able to prove both upper and lower bounds on the first two moments\footnote{As noted in Section \ref{sect.bounds}, the upper bound on the variance technically remains a conjecture.} of the longest path distribution. Since normally distributed costs occur in many applications and the method is both cheap and somewhat similar to the approaches discussed previously in this section, we describe it in depth here.

The bounds are achieved by recursively computing four number sequences $\underline{m_i}$, $\overline{m_i}$, $\underline{s_i}$ and  $\overline{s_i}$ such that $\underline{m_i} \leq \mu_{L_i} \leq \overline{m_i}$ and $ \underline{s_i} \leq \sigma_{L_i} \leq \overline{s_i}$ for all $i = 1, \dots, n$. Clearly, by taking $\underline{m_1} = \overline{m_1} = \E[\pi_1]$ and $\underline{s_1}^2 = \overline{s_1}^2 = Var[\pi_1]$ we can achieve the desired bounds for $L_1$. (As ever, we can work backward instead in which case the analogous results hold for the index $n$.) Now we suppose that all of the upper and lower bounds have been computed for all of the parents of a given node $t_i$ and consider how we can construct  $\underline{m_i}$, $\overline{m_i}$, $\underline{s_i}$ and  $\overline{s_i}$. The variance bounds are relatively straightforward. The lower bound is given by
\begin{equation}
\underline{s_i^2} =\left\{
\begin{array}{@{}ll@{}}
\underline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}], \quad  \text{if $P_i = \{s_h\}$,} \\
0,  \quad \text{ otherwise},
\end{array}\right.
\label{eq.si_under}
\end{equation}
reflecting the fact that the variance, as computed by equation \eqref{eq.clark_max_sigma}, can be reduced to an arbitrary extent by a maximization (which needs to be performed for multiple parents). The (conjectured) upper bound is similarly a result of this fact,
\begin{align}
  \label{eq.si_over}
  \overline{s_i^2} = \max_{h \in P_i}\{ \overline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]\}.
\end{align}
The bounds on the expected value are somewhat more complex. First, define a function $h$ by
\begin{align*}
  h(\mu_i, \sigma_i, \mu_k, \sigma_k) = \mu_i \Phi(\overline{\beta}) + \mu_k \Phi(-\overline{\beta}) + \overline{\alpha} \phi(\overline{\beta}),
\end{align*}
where $\overline{\alpha} = \sqrt{\sigma_i^2 + \sigma_k^2}$ and $\beta = (\mu_i - \mu_k)/ \overline{\alpha}$. Per equation \eqref{eq.clark_max_mu}, $h$ is the expected value of the maximization of two {\em independent} normally distributed RVs $X_i \sim N(\mu_i, \sigma_i^2)$ and $X_k \sim N(\mu_k, \sigma_k^2)$. Now, suppose that we have a set of (not necessarily independent) normally distributed RVs $X_1, X_2, \dots, X_r$, where each $X_i \sim N(\mu_i, \sigma_i^2)$ and $\sigma_1 \leq \sigma_2 \leq \dots \leq \sigma_r$. Define two functions $\underline{f}$ and $\overline{f}$ by the recursions,
\begin{align*}
  &\underline{f}(X_1) = \overline{f}(X_1) = \mu_1, \\
  &\underline{f}(X_1, X_2) = \overline{f}(X_1, X_2) = h(\mu_1, \sigma_1, \mu_2, \sigma_2), \\
  &\underline{f}(X_1, \dots, X_r) = h(\underline{f}(X_1, \dots, X_{r - 1}), 0, \mu_r, \sigma_r), \\
  &\overline{f}(X_1, \dots, X_r) = h(\overline{f}(X_1, \dots, X_{r - 1}), \sigma_{r - 1}, \mu_r, \sigma_r).
\end{align*}
Then, for all $i = 2, \dots, n$, if we define
\begin{align*}
  \underline{m_i} &= \underline{f}(\{ \underline{X_h} \}_{h \in S_i}),
\end{align*}
where
\begin{align*}
  \underline{X_h} &\sim N(\underline{m_h} + \E[\pi_{hi}] + \E[\pi_{i}], \; \underline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]),
\end{align*}
and
\begin{align*}
  \overline{m_i} &= \overline{f}(\{\overline{X_h}\}_{h \in S_i}),
\end{align*}
where
\begin{align*}
  \overline{X_h} \sim N(\overline{m_h} + \E[\pi_{hi}] + \E[\pi_{i}], \; \overline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]),
  \end{align*}
we have 
\begin{align*}
  \underline{m_i} \leq \mu_{L_i} \leq \overline{m_i}.
\end{align*}
(Here we are assuming that the sets $\{\underline{X_h}\}_{h \in S_i}$ and $\{\overline{X_h}\}_{h \in S_i}$ are ordered in such a way that the inequality constraints on the variances is satisfied.)


\section{Other heuristics}
\label{sect.other_methods} 

% MC part is same as in previous chapter - where best to put it?

{\em Monte Carlo} methods have a long history in approximating the longest path distribution of PERT networks, dating back to at least the early 1960s \cite{van63}. The idea is to simulate the realization of all RVs and evaluate the longest path of the resulting deterministic graph. This is done repeatedly, giving a set of longest path instances whose empirical distribution function is guaranteed to converge to the true distribution by the Glivenko-Cantelli theorem \cite{can16}. Furthermore, analytical results allow us to quantify the approximation error for any given the number of realizations---and therefore the number of realizations needed to reach a desired accuracy. The major disadvantage is the cost, particularly when the number of realizations required is large, although modern architectures are well-suited to MC methods because of their parallelism so this problem may no longer be as acute as it once was. At any rate, in this chapter, we typically only use MC methods in order to obtain reference solutions.
% We call it a heuristic since the solutions are not exact by definition, although we do use them as a reference since they are guaranteed to converge...
% Maybe put this first.
% The oldest and most reliable way to approximate the longest path dist...

If the graph is {\em series-parallel} then we can compute the exact distribution of the longest path length in polynomial-time through a series of reductions \cite{dod85,mar65}. If this isn't the case, similar methods have been proposed that give approximations to the distribution \cite{dod85,lud01}, however these tend to be less accurate than Monte Carlo-based methods and more expensive than the those based on the normality assumption \cite{can16}.
% Too abrupt in light of stuff about series parallel graphs in bounds section. Combine with there.
% Also Spelde's heuristic bound on the cdf...

% One speculative approach that might be useful is to consider extreme value theory... The problem is that it isn't clear how to characterize the distribution. Paper by Berman (and other one) seems to suggest that max of dependent normals will also tend to Gumbel but don't know anything about the correlations...


\section{Updating makespan estimates}
\label{sect.updating}

% TODO: rewrite all this, no longer using this approach (see slides for viva presentation). "A big advantage of the correlation based approach is that we can quickly update the makespan/longest path estimate in response to realized data..."
% Mention emapse somewhere - e.g., we don't repeat the work of Canon, who did the best empirical comparison of different methods for computing the longest path distribution... Many of the methods discussed here were implemented in their emapse package... We chose to implement our own smaller-scale simulator for continuity with earlier work in this thesis...
% This is a question that is particularly relevant when large, unexpected delays occur and decisions may need to be made as to whether to continue following the computed schedule at all.

Estimating the length of a schedule with stochastic costs before its execution has been widely-studied, as the examples in previous sections illustrate. We therefore focus here on a different but related problem: how can schedule makespan estimates be quickly updated {\em during} execution? This would be particularly useful in situations such as when a large unexpected delay occurs. More precisely, the scenario we consider is as follows. Given a schedule $\pi$, we computed a complete set of task finish times estimates $L_i \sim N(\mu_i, \sigma_i^2)$ for all $i = 1, \dots, n$ before runtime using one of the Clark equation-based methods discussed in Section \ref{sect.normality}. At some point in time $T$ during the schedule execution we want to compute a new, more accurate estimate of the makespan based on the costs which have been observed thus far. How do we do this as quickly and accurately as possible?

Effectively, at time $T$ the schedule graph $G_s$ can be divided into two distinct subgraphs: one corresponding to those tasks that have been completed and the other to those that have not. Define $C_T$ to be the set of indices corresponding to tasks that have completed by time $T$ and $U_T$ to be the set of indices corresponding to tasks that are still not done. Furthermore, define $C_T^* \subseteq C_T$ to be the set of indices of tasks which have been completed but at least one of their parents has not---i.e., in some sense the boundary of the realized and unrealized sections of the graph.
% something about the first having multiple exit tasks and the second multiple entry tasks?

Since all cost RVs corresponding to tasks indexed by $C_T$---and the edges between them---have been realized, we can compute the realized finish times $\ell_i$ for the corresponding tasks in the usual manner for scalar costs. The question then remains of how we compute an updated set of longest path estimates $L_k'$ for all $k \in U_T$, including a new final makespan estimate $L_n'$. We outline different possible approaches to this problem in the following three sections.

\subsection{Estimating the remaining time}
\label{subsect.remaining}

The most straightforward approach is to simply consider the unrealized portion of the graph separately and compute the longest path through it, starting from any of the boundary tasks indexed by $C_T^*$, using any heuristic method; a new longest path estimate which passes through the given boundary task is then the sum of the realized longest path up to and including the task, plus the estimated longest path through the remaining unrealized subgraph. More efficiently, rather than initially computing values $L_i$ that represent longest path lengths from the source to a task (inclusive), we can compute a sequences of values $R_i$ that represent the longest paths from the tasks to the sink (exclusive)---i.e., estimates of the remaining time until the entire schedule has been completed. In particular, we set $R_n = 0$, then work backward and recursively compute  
\begin{align*}
  R_i = \max_{k \in S_i} \{ \pi_{ik} + \pi_k + R_k  \}
\end{align*}
for all other tasks, where the moments of the maximization are computed using the Clark formulae in a manner corresponding to whichever of Sculli's method, CorLCA or CorDyn we decide to use. Note that since the $R_i$ do not include the cost of task $t_i$ the full schedule makespan estimate is $R_1 + \pi_1$.

(Minor changes need to be made to CorLCA and CorDyn in order to estimate the correlations when working backward through the DAG. For example, in CorLCA, rather than the lowest common ancestors of two tasks, we want the deepest common descendants. However these changes are fairly straightforward. As an aside though, fairly significant differences are sometimes apparent between the makespan moment estimates computed forward and backward through the DAG for all three heuristics, particularly with regard to the variance. For example, we found that for Cholesky schedule DAGs, the variance was always smaller when the makespan is computed backward. We attribute this to the fact that the average number of task children exceeds the average number of task parents so the corresponding maximizations contain more terms; since these are computed pairwise and the effect of \eqref{eq.clark_max_sigma} is to decrease the variance, this may not be entirely surprising.) 

The advantage of this approach is that at time $T$ the estimated longest path which passes through task $t_i$, where $i \in C_T^*$, is simply given by $L_i' = \ell_i + R_i$ and, in particular, a new estimate of the makespan can be computed through
\begin{align*}
  L_n' = \max_{i \in C_T^*} \{ \ell_i + R_i  \}.
  \end{align*}
This maximization can be done in the same manner as the calculation of the $R_i$, using the same set of correlation coefficients (or not, if using Sculli's method).

\subsection{Updating the makespan directly}
\label{subsect.corr_update}

Another possible method for updating the final makespan estimate makes use of the following result.
\begin{prop}
	Let $u$ be a normally distributed vector with mean $\bar{\mu}$ and covariance $\Sigma_u$, $u \sim N(\bar{\mu}, \Sigma_u)$, and suppose that $u = (v, w)$. Then 
	\begin{align*}
	(w \mid v) \sim N \big( \bar{w} + \Sigma_{wv}\Sigma_{vv}^{-1} (v - \bar{v}), \enspace  \Sigma_{ww} - \Sigma_{wv} \Sigma_{vv}^{-1} \Sigma_{vw} \big).
	\end{align*}
\end{prop}
Note that if all of the linear correlation coefficients $\rho_{uv}$ are known, we can use the definition $\rho_{uv} = \Sigma_{uv} / \sigma_u \sigma_v$ to find $\Sigma_{uv}$.

This proposition is useful because we have been implicitly assuming that there is a joint normal distribution across the entire set of finish times $L_i$ due to their dependencies. Furthermore, we can estimate the correlation coefficients between finish times at any two tasks using, for example, the correlation tree approach of CorLCA. This means that we can update the final makespan estimate using only the observed finish times of the tasks indexed by $C_T^*$. For compactness of notation let $\rho_{in} = \rho_{ni}$ be the linear correlation coefficient between $L_i$ and $L_n$. Suppose that task $t_i$ has finished at time $\ell_i$. Then we can compute a new estimate $L_n^i$ of the final makespan by applying the above result as follows,
\begin{align*}
L_n^i &\sim N \bigg( \mu_{n} + \frac{\rho_{ni} \sigma_{n} \sigma_{i}}{\sigma_{i}^2} (\ell_i - \mu_{i}), \enspace \sigma_{n}^2 - \frac{\rho_{ni} \sigma_{n} \sigma_{i} \cdot \rho_{in} \sigma_{i} \sigma_{n}}{\sigma_{i}^2} \bigg) \nonumber\\
&\sim N \bigg(\mu_{n} + \frac{\rho_{ni} \sigma_{n}}{\sigma_{i}} (\ell_i - \mu_{i}), \enspace (1 - \rho_{ni}^2) \sigma_{n}^2 \bigg).
\end{align*}
We do this for all $i \in C_T^*$ and then compute their maximum (using the same method as before to estimate the correlation coefficients, if they are not already known) in order to obtain a new estimated final makespan $L_n'$, 
\begin{align*}
  L_n' = \max_{i \in C_T^*} \{ L_n^i  \}.
  \end{align*}

\subsection{Propagating updates forward}
\label{subsect.propagating}

Rather than updating the finish time of the exit task---and therefore the makespan---directly, we can instead move forward through the DAG and update the finish time estimates for all unrealized tasks. This is slightly more expensive of course but potentially more accurate. Now, in principle the updated finish times can be computed for each task $t_i$, where $i \in U_T$, using equation \eqref{eq.Li} in the usual manner. However, there are essentially three different cases that we need to consider, depending on the status of the terms in the maximization.
\begin{enumerate}
\item Both $\pi_{hi}$ and $L_h$ have been realized for all $h \in P_i$.
\item Both $\pi_{hi}$ and $L_h$ have been realized for some $h \in P_i$ but not others. 
  \item Both $\pi_{hi}$ and $L_h$ have been realized for none of the parents.
  \end{enumerate}
  In the first instance, the sums of $\pi_{hi}$ and $L_h$ are now deterministic so the maximization is just done over a set of scalars and is therefore straightforward. Similarly, in the third case, all of the sums are unrealized RVs so we can just use Clark's equations again to compute the new finish time estimate.

The second case is more interesting. The problem basically reduces to how we compute the maximum of a set of RVs, some of which have been realized and others which have not. For notational ease, let $Z_h = \pi_{hi} + L_h$ and $M_i = \max_{h \in P_i} \{ Z_h  \}$.  Let $X_i$ be the maximum over the subset of parents for which $Z_h$ has been realized. Now, we know that $M_i > X_i$ since at least some of the $Z_h$ have not been realized yet. Furthermore, we have already computed an estimate of $L_i = \pi_i + M_i$, where $M_i$ is assumed to be roughly normal, so we can also explicitly form $M_i \sim N(\mu_{M_i}, \sigma_{M_i}^2)$. We want to find a new finish time estimate
\begin{align}
  \label{eq.dash_Li}
  L_i' = \pi_i + (M_i | M_i > X_i). 
\end{align}
Given that $M_i$ is assumed to be Gaussian, we can model the term on the right as a truncated Gaussian. Let $a = (X_i - \mu_{M_i}) / \sigma_{M_i}$ and $b = 1 - \Phi(a)$, where $\Phi$ is the unit normal cdf as before. Then the first two moments of $(M_i | M_i > X_i)$ are given by
\begin{align*}
  \E[M_i \mid M_i > X_i] = \mu_{M_i} + \frac{\sigma_{M_i}\phi(a)}{b}
\end{align*}
and
\begin{align*}
  Var[M_i \mid M_i > X_i] = \sigma_{M_i}^2 \bigg[ 1 + \frac{a\phi(a)}{b} - \bigg( \frac{\phi(a)}{b} \bigg)^2    \bigg].
\end{align*}
Using these expressions, we can now compute \eqref{eq.dash_Li}, and therefore work through the remainder of the DAG updating the finish time estimates for all tasks that have not yet completed. 

\section{Numerical experiments}
\label{sect.results}

In order to study the problem of estimating the longest path of a stochastic graph---i.e., the makespan distribution of stochastic schedules---we created a simple software package which implements several of the heuristic methods discussed so far in this chapter. As in previous chapters, the source code is written in {\tt Python} and is available in its entirety on Github\footnote{\href{https://github.com/mcsweeney90/stochastic-longest-path}{{\tt \small https://github.com/mcsweeney90/stochastic-longest-path}}}. Much more sophisticated software along these lines already exists, such as the {\em Emapse} package from Canon and Jeannot (citation). However, we decided to create our own, both as a learning exercise and for ease of integration with other work in this thesis. In this section, we describe the results of small-scale numerical experiments performed in this framework concerning various aspects of the longest path estimation problem.

\subsection{Before runtime}
\label{subsect.before_runtime}

Exhaustive comparisons of heuristic methods for estimating the longest path distribution before any RVs have been realized have been done before in the literature, with the best example again probably being the work of Canon and Jeannot \cite{can16}. Rather than repeating those investigations, we take a narrower view and focus on a single family of graphs based on schedules for a widely-used application in scientific computing, namely Cholesky factorization, on an accelerated target platform.

More specifically, the graphs are constructed from schedules computed by the static HEFT heuristic for Cholesky task graphs with between $35$ and $11480$ tasks (corresponding to matrix tilings from $5 \times 5$ to $40 \times 40$, with the dimensions increasing in increments of $5$). The target platform is the {\em Single GPU} platform from Chapter X, comprising 7 CPU resources and one GPU. The schedule is initially computed as in Chapter X, which then determines the topology of the schedule graph---i.e., where we add the disjunctive edges to the original task graph. The node and edge weights of the schedule graph are then modeled as random variables with means and variances given by the sample means and variances we observed for the relevant tasks in the experimental testing we described in Chapter X, with tile size $128$ and no asynchronous data transfers being assumed.

Taking the main conclusions of the more wide-ranging study by Canon and Jeannot as given, at least in the general case, the overall aim of our small-scale investigation is basically to determine whether the improved moment estimates produced by the correlation-aware heuristic CorLCA rather than Sculli's method are worth the extra computational cost for the realistic example schedule graphs considered here. In addition, we also briefly consider how useful some of the cheaper bounds are in this case, with a view to their possible use for making scheduling decisions.

\subsubsection{The normality assumption}
\label{subsubsect.results_normality}

Other studies have thoroughly investigated how close to normal the longest path distribution actually tends to be for randomly-generated schedule DAGs, so we only treat this topic very briefly here. Our conclusions for the Cholesky schedule graphs are that the longest path distribution does very much tend to normality as the number of tasks increases and the costs themselves are sampled from distributions closer to normal.

In order to estimate the true longest path distribution in this section---and the following two---we use the Monte Carlo method with $10^5$ samples. Given the number of samples, these estimates are likely to be very good for the smallest graphs but perhaps slightly less accurate for the largest ones (although we expect them to still be at least fairly good).

First we assume that all individual costs are normally distributed. Now, there are several standard statistical tests for normality, such as Shapiro-Wilks, Anderson-Darling or Kolmogorov-Smirnoff, etc, but it is perhaps more instructive here to consider the longest path distribution visually. Figure X shows how the shape of empirical distribution changes as the number of tasks in the DAG increases... We see that the distribution does indeed more closely resemble the normal bell curve as the size of the DAG increases...

\begin{figure}
	\centering	
	\includegraphics[scale=1.0]{normality_placeholder.png}
	\caption{Placeholder--TODO.}	
	\label{plot.normal_assum_normal}
      \end{figure}
      % TODO: just a placeholder, better image.

% TODO: Extend this - more analysis of the distribution itself.

\subsubsection{Kamburowski's bounds}
\label{subsubsect.results_bounds}

Although there are many bounds on the longest path distribution in the literature, given our overriding interest in practical scheduling methods and our experience in the previous chapter with Fulkerson's bounds on the expected value---which were impractically expensive even for relatively small graphs---we decided to eschew methods which require the evaluation of complex integrals. Similarly, bounds based on graphs reductions may be prohibitively expensive. Hence we decided to focus here on bounds that can be computed through simple numerical schemes, such as the classic PERT-CPM bound on the mean and Kamburowski's bounds on the first two moments (when costs are normally distributed). The latter does require the evaluation of the unit normal cdf, but this is a standard part of most good numerical software libraries, so can be computed efficiently.

Table \ref{tb.mean_bounds} shows how tight the PERT-CPM and Kamburowski bounds on the expected value are for the Cholesky graph set, where the reference solution is computed using the Monte Carlo method with $10^5$ samples under the assumption that all individual RVs are normally distributed (although it should also be noted that results were extremely similar when costs are Gamma distributed, see previous section). We see that the lower bounds are very tight, with Kamburowski only improving on PERT-CPM very slightly. This may be down to the topology and cost structure of the Cholesky graphs, which is relatively simple, although it should be noted that in general it is not the case that complex applications necessarily have complex task graphs. The upper bounds from Kamburowski are much looser, although even in the worst case no more than $19\%$ greater than the true value. 
% TODO: gamma costs.

\begin{table}
	\caption{Tightness of bounds on the expected value for Cholesky DAGs, as a percentage of the reference expected value.} 
	\begin{center}	
		\begin{tabular}{c c c c c c c c c}
                  \cmidrule{1-9}
                  & \multicolumn{8}{c}{DAG size} \\
                  \cmidrule{2-9}
			Bound & $35$ & $220$ & $680$ & $1540$ & $2925$ & $4960$ & $7770$ & $11480$\\
			\cmidrule{1-9}
			PERT-CPM & $99.5$ & $98.9$ & $98.5$ & $98.7$ & $99.2$ & $99.2$ & $99.4$ & $99.5$\\
                  K. (lower) & $99.9$ & $99.4$ & $98.9$ & $99.1$ & $99.4$ & $99.3$ & $99.5$ & $99.6$\\
                  K. (upper) & $100.9$ & $104.0$ & $110.3$ & $118.7$ & $116.6$ & $114.0$ & $112.4$ & $111.5$\\
			\bottomrule
		\end{tabular}
		\label{tb.mean_bounds}
	\end{center}	
      \end{table} 

      Unfortunately, the variance bounds given by Kamburowski's method are considerably looser in both directions, potentially to the extent of being impractical when making scheduling decisions. Figure \ref{plot.variance_bounds} illustrates how wide the bounds are for the Cholesky graphs... 

      \begin{figure}
	\centering	
	\includegraphics[scale=1.0]{variance_bounds.png}
	\caption{Kamburowski's bounds on the variance for the Cholesky graph set. Reference solution given by solid line.}	
	\label{plot.variance_bounds}
      \end{figure}

      % TODO: just a comment that results were very similar for Gamma costs?

% Probably the cheapest possible bound to compute is the PERT bound so that's the natural comparison...



\subsubsection{Do correlations need to be considered?}
\label{subsubsect.results_correlations}

The question we consider here is, although CorLCA generally obtains superior estimates of the makespan distribution, are these gains significant enough to be worthwhile in a scheduling heuristic?

\subsection{Updating the finish time}
\label{subsect.results_updating}

Consider different permutations (fraction of tasks initially realized, distributions of the costs, etc) in a systematic manner and compare with MC estimates... 

\section{Conclusions}
\label{sect.conclusions}

Conclusions go here. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{myplain2-doi}
\bibliography{references,strings}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
