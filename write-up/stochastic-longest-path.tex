% !TeX document-id = {54177b55-cdde-488b-90fe-107922d59049}
\documentclass[12pt]{article}

\usepackage{a4} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[]{xcolor}
\usepackage{graphicx}
\usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=hotpink]{hyperref}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{caption}
\usepackage[british]{babel}
\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage{epstopdf}
\usepackage{mathtools} % for :=
\usepackage{subfig}
\usepackage[most, minted]{tcolorbox}
\usepackage{mdwlist}
\tcbuselibrary{listings}

\newtcblisting{myminted}{%
	listing engine=minted,
	minted language=python,
	listing only,
	breakable,
	enhanced,
	minted options = {
		linenos, 
		breaklines=true, 
		breakanywhere, 
		fontsize=\footnotesize, 
		numbersep=2mm,
		tabsize=2
	},
	overlay={%
		\begin{tcbclipinterior}
			\fill[gray!25] (frame.south west) rectangle ([xshift=4mm]frame.north west);
		\end{tcbclipinterior}
	}   
}
\BeforeBeginEnvironment{minted}{\begin{tcolorbox}[breakable, enhanced]}%
	\AfterEndEnvironment{minted}{\end{tcolorbox}}%


\graphicspath{{images/}}

\title{Approximating the makespan distribution of stochastic schedules} % Think of a better title...
\author{Thomas McSweeney%
	\thanks{%
		School of Mathematics,
		University of Manchester,
		Manchester, M13 9PL, England
		(\texttt{thomas.mcsweeney@postgrad.manchester.ac.uk}).
	}
}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}
\def\nbyn{n \times n}
\def\mbyn{m \times n}
\def\l{\lambda}
\def\norm#1{\|#1\|}      
\def\normi#1{\|#1\|_1}
\def\normo#1{\|#1\|_{\infty}}
\def\Chat{\widehat{C}}
\def\e{eigenvalue}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}
\def\diff{\mathop{}\!\mathrm{d}}

% \DeclareMathOperator{\diag}{diag}   % Requires amsmath.
\def\diag{\mathop{\mathrm{diag}}}     % If not using amsmath.
\def\trace{\mathop{\mathrm{trace}}}   % If not using amsmath.

\def\At{\widetilde{A}}
\def\normt#1{\|#1\|_2}

% Set up lemma environment and its numbering.
\newtheorem{lemma}{Lemma}[section]

\def\proof{{\bf Proof}. \ignorespaces}
\def\qedsymbol{\vbox{\hrule\hbox{%
			\vrule height1.3ex\hskip0.8ex\vrule}\hrule}}
\def\endproof{\qquad\qedsymbol\medskip\par}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}

\allowdisplaybreaks[1]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% For fine-tuning spacing in \sqrt etc=.  From \cite[p.~155]{knut99}.
% In math mode, @ will act as a macro that adds 1 unit of space.
% By comparison, \, skips 3mu.

\mathcode`@="8000 % Make @ behave as per catcode 13 (active).  TeXbook p. 155.
{\catcode`\@=\active\gdef@{\mkern1mu}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcounter{mylineno}
\makeatletter
\let\oldtabcr\@tabcr
\def\nonumberbreak{\oldtabcr\hspace{3.5pt}}
\def\mynewline{\refstepcounter{mylineno}%
	\llap{\footnotesize\arabic{mylineno}\hspace{5pt}}%
}
\def\lineref#1{\footnotesize\ref{#1}}
% Next macro adapted from latex.ltx
\gdef\@tabcr{\@stopline \@ifstar{\penalty%
		\@M \@xtabcr}\@xtabcr\mynewline}
\def\myvspace#1{\oldtabcr[#1]\mynewline}
\newenvironment{code}{%
	% Swap `:' and `colon'...
	\mathcode`\:="603A  % TeXbook pp 134, 154, 359 (top)
	% For original colon     \mathcode`\:="303A  % TeXbook p 344
	\def\colon{\mathchar"303A}
	\setcounter{mylineno}{0}
	\par
	\upshape
	\begin{list} % To give indentation
		{} {\leftmargin = 1cm}
		\item[]
		\begin{tabbing}
			
			% Default tab stops
			\hspace*{.3in} \= \hspace*{.3in} \=
			\hspace*{.3in} \= \hspace*{.3in} \= \kill
			\mynewline
		}{\end{tabbing}\end{list}}
\makeatother


\addto\captionsbritish{	\renewcommand{\bibname}%
	{References}%TODO: make sure reference style is consistent.
}

\definecolor{hotpink}{rgb}{0.9,0,0.5}

\begin{document}
	\maketitle 	


\section{Introduction}
\label{sect.intro}

% Questions for Neil: longest path or makespan throughout?

For any optimization problem, we obviously need to be able to evaluate how good any given solution is with regards to the optimization criteria in order to find an optimal, or otherwise acceptable, solution. The scheduling problems we consider here are clearly no exception: we want to know how good a computed schedule is, whether there are other schedules which are better, and so on. Evaluating the makespan of a given schedule would appear to be a straightforward problem---and so it is, when the computation and communication costs are static. But if costs are {\em stochastic} then this may no longer be the case.

Now, as long as it specifies the execution order of tasks on processors, any schedule $\pi$ for an application with task DAG $G$ can be represented by a {\em schedule graph} $G_{\pi}$ such that the longest path of $G_{\pi}$ is equal to the makespan of $\pi$: $G_\pi$ contains all the same vertices and edges as $G$, plus additional zero-weight {\em disjunctive} edges that indicate the execution order of the tasks on their chosen processors; the other weights of $G_\pi$ are induced by the processor selections of $\pi$. There's some flexibility in how we add the disjunctive edges; the most straightforward way to do it is to simply add an edge between a task $t_i$ and the task $t_h$ which is executed immediately before $t_i$ on its chosen processor if an edge does not already exist between the two.  
% We can interpret the entire scheduling problem as a question of how to add disjunctive edges such that the longest path is minimized...

For example, consider the schedule $\pi$ from Figure X and the graph $G$ in Figure Y. We can construct the associated graph $G_\pi$ as shown in Figure Z. From now, we use the notations $\pi_i$ and $\pi_{ik}$ to represent the computation cost of task $t_i$ and the communication cost between tasks $t_i$ and $t_k$ under the schedule $\pi$, respectively. Assuming, without loss of generality, that there is only one entry task $t_1$ and one exit task $t_n$, to compute the longest path through $G_\pi$---and therefore the makespan of $\pi$---we compute a sequence of numbers $L_i$ defined by $L_1 = \pi_1$ and
\begin{align}
  \label{eq.Li}
  L_i = \pi_i + \max_{h \in P_i}\{ \pi_{hi} + L_h\}
\end{align}
for all other $i = 2, \dots, n$. The longest path of $G_\pi$ is then given by $L_n$. In the example above, we have... so we see that $L_n$ is indeed equal to the schedule makespan. Computing the longest path using \eqref{eq.Li} is an $O(n + e) \approx O(n^2)$ operation, which depending on the size of the DAG may be expensive but is at least polynomial. (Of course, we could work backward through the DAG by setting $L_n = \pi_n$ and doing the maximization over the set of task children in \eqref{eq.Li} instead; the makespan would then be given by $L_1$ but the procedure is otherwise equivalent.)

Unfortunately, in practice, schedule costs are almost never known precisely before runtime. Typically, the best we can do is estimate the probability distribution that we believe they follow---i.e., we model the costs as random variables (RVs)---based either on theoretical results or a relevant body of data. But if costs are RVs rather than fixed scalars, it is obviously impossible to specify the precise time at which each task should begin execution so at this point we need to redefine what we mean by a schedule: here, we assume that a schedule $\pi$ is a mapping from tasks to processors that specifies only which tasks each processor should execute and in what order; the processor then executes the next scheduled task as soon as it is able. Conceptually, we can view this as a processor being assigned an ordered queue of tasks before runtime and only being allowed to pop the task currently at the head of the queue. 

This definition means that even though costs are stochastic, the disjunctive graph $G_\pi$ has the same topology as it would in the static case. However, since all costs are RVs, the longest path is also now an RV. Unfortunately, it is unclear how we should go about computing its distribution. Fundamentally, the problem is that even if all of the graph weights are independent of one another, path lengths typically aren't because of common nodes and edges. So if we attempt to apply \eqref{eq.Li} we soon run into difficulty because computing the maximum of a set of dependent RVs is intractable, with very rare exceptions. Furthermore, this presupposes that all individual cost distributions (and summations thereof) are fully known, which is rarely true in practice. Formalizing this intuitive difficulty, Hagstrom proved that computing the longest path distribution of a stochastic graph, or even just its expected value, is a $\#P$-complete problem when all weights are discrete RVs \cite{hag88}, and there is little reason to assume it is any easier in the continuous case.      

Given the difficulty of the problem, bounds or heuristic approximations for the longest path distribution---and therefore the schedule makespan distribution---are typically needed instead. In this chapter, we give a brief overview of various methods that have been employed for this purpose, with a particular focus on a family of efficient heuristics which are likely the most practical approach in the context of stochastic scheduling. Although useful on its own merits, in the context of this research this chapter functions as a bridge between earlier chapters which focus on computing schedules when costs are assumed to be known exactly and the later chapters in which the aim is to compute a schedule that is robust to the effects of uncertain cost estimates. We will see that many of the techniques discussed here underlie both existing stochastic scheduling heuristics and the new heuristic that we propose in the next chapter. This chapter is intended primarily as an literature review so there is relatively little new research, although we do take an extended look at a problem that has rarely been addressed before: how do we quickly update a longest path estimate---i.e., an estimated schedule makespan---as realizations become apparent at runtime? 

The problem of computing the distribution of the longest path through a DAG with stochastic weights was first studied in the context of {\em program evaluation review technique} (PERT) network analysis \cite{mal59}. Since a PERT network is essentially just what we have referred to here as a schedule graph, the longest path also typically represents an overall finish time---i.e., the makespan---and nodes tasks that must be completed. However, the stochastic longest path problem has also been studied in more dissimilar research areas such as digital circuit design \cite{bla08}, so in this chapter we typically use the more general {\em longest path} rather than {\em makespan}.  
% better reference for digital circuit design? 

\section{Bounds}
\label{sect.bounds}

Although computing the longest path distribution exactly is usually impossible, bounds on various quantities of interest may be computed much more cheaply. Depending of course on the context, these may be tight enough to be useful.

Some of the oldest results are concerned with the expected value. In particular, as we have already seen in previous chapters, a lower bound which dates back to the earliest days of PERT analysis can be computed in $O(n^2)$ operations by replacing all weight RVs with their expected value and proceeding as in \eqref{eq.Li}---i.e., define $u_1 = \E[\pi_1]$ and
\begin{align}
  \label{eq.ui}
  u_i = \E[\pi_i] + \max_{h \in P_i}\{ \E[\pi_{hi}] + u_h\}
\end{align}
for all other $i = 2, \dots, n$, then we have $u_i \leq \E[L_i]$ and in particular $u_n \leq \E[L_n]$. We will refer to this as the {\em critical path method} (CPM) bound. Furthermore, we also saw in the previous chapter that a tighter bound can be found through Fulkerson's \cite{ful62} alternative method, which was extended to continuous weights by Clingen \cite{cli64} and later improved by Elmaghraby \cite{elm67}. Although this approach as generalized by Robillard and Trahan \cite{rob76} can tighten the lower bound almost arbitrarily, the computational cost of even Fulkerson's bound can be prohibitive in some cases, as suggested by our experience in the previous chapter.    
% cpm bound since that was the context in which...

All of those methods provide only lower bounds for the expected value. However, Dodin's lower bound on the distribution function also induces an upper bound on the expected value \cite{dod85} (see below).  Furthermore, if all graphs weights follow {\em New Better Than Used in Expectation} (NBUE)\footnote{A concept from reliability theory, referring to distributions representing object lifetimes such that, at any given time, the expected value of the remaining lifetime is smaller than the expected value of the entire lifetime. Certain common distributions such as Erlang and uniform are NBUE, as are many others such as Gamma under restricted parameter regimes.} distributions, then an upper bound can be computed by replacing all weights by exponentially distributed RVs with the same means and then performing a series-parallel reduction \cite{kam85a, yaz91}. This approach has the advantage that only the expected values of all graph weights are necessary. 

Alternatively, if all node and edge weights are normally distributed, then Kamburowski \cite{kam85} was able to prove both lower and upper bounds on the expected value. However, his bounds---although exact when weights are normal---are conceptually very similar to a class of heuristics discussed in the following section, so will be described in more detail there. Kamburowski also proved a lower bound on the variance, as well as a conjectured upper bound, for the case of normally distributed weights. These are the only formal bounds on moments higher than the first that we are aware of, although the upper is unproven and the lower is very loose.

Rather than just the moments, we may be more interested in bounds on the cumulative distribution function (cdf) $F_{L_n}$ of the longest path, where the bounds indicate (first-order) {\em stochastically dominant} relationships between the underlying RVs. In particular, we say that $B$ stochastically dominates $L_n$ if $F_{L_n}(z) = \P[L_n \leq z] \leq \P[B \leq z] = F_B(z) \; \forall z$. For convenience, from now on we simply write $F_{L_n} \leq F_B$ to represent the previous expression, so that the aim here is to determine $F_b$ and $F_B$ such that $F_b \leq F_{L_n} \leq F_B$.

The first bounds on the distribution of the longest path were provided by Kleindorfer \cite{kle71}. Now, distribution functions for the sum and maximization of {\em independent} random variables are easily computed. In particular, suppose $X$ and $Y$ are independent and define $S = X + Y$ and $M = \max(X, Y)$. Then $F_S$ is computed through the convolution
\begin{align}
  \label{eq.cdf_convolution}
  F_S(z) = \int_{-\infty}^{\infty} F_Y(z - t) f_X(t) \; \diff t,
\end{align}
where $f_X$ is the probability density function of $X$, and $F_M$ via the product
\begin{align}
  \label{eq.cdf_product}
  F_M(z) = F_X(z) \times F_Y(z),
\end{align}
both of which can be readily approximated through standard numerical methods. Kleindorfer's upper bound is determined by working through the graph in the usual manner and assuming path independence---i.e., computing \eqref{eq.Li} using \eqref{eq.cdf_convolution} and \eqref{eq.cdf_product} for sums and maximizations, respectively. A corresponding lower bound is given by effectively disregarding all maximizations and simply using one of the operands.

Inspired by the observation that Kleindorfer's upper bound is exact when all path lengths are independent, Dodin \cite{dod85} combined the method with a sequence of series-parallel reductions such that the graph is transformed to a single edge whose associated distribution function bounds the longest path distribution from above. If the graph is already series-parallel then the bound is exact. Moreover, Dodin showed that the bound is tighter than Kleindorfer's, and, as noted above, that a corresponding lower bound on the expected value can be inferred.

Exhaustive empirical investigations by Ludwig, M{\"o}hring and Stork \cite{lud01} and Canon and Jeannot \cite{can16} suggest that the bounds of Kleindorfer and especially Dodin are usually tight, so they may be useful as approximations of the distribution function in addition to bounds. However, although both methods run in polynomial time, they tend to still be significantly more expensive than heuristics based on the Central Limit Theorem (see Section \ref{subsect.normality}), without pronounced improvements in accuracy, so are typically of less interest from a scheduling perspective and are not included in comparisons here. 

%Reference to Bein? Shogan?
%good reference for stochastic dominance.

\section{Heuristics}
\label{sect.heuristics}

Rather than a formal bound, in many cases it may be more useful to simply obtain a good estimate of the longest path distribution. To that end, many heuristic approaches have been proposed. In this section we discuss some of those which may be of particular interest.

\subsection{Monte Carlo}
\label{subsect.monte_carlo} 

% MC part is same as in previous chapter - where best to put it?

{\em Monte Carlo} (MC) methods have a long history in approximating the longest path distribution of PERT networks, dating back to at least the early 1960s \cite{van63}. The idea is to simulate the realization of all weight RVs and then evaluate the longest path of the resulting scalar graph. This is done repeatedly, giving a set of longest path instances whose empirical distribution function is guaranteed to converge to the true distribution by the Glivenko-Cantelli theorem\footnote{Despite this convergence in the limit, we refer to MC as a heuristic as any solutions obtained in practice will only ever be approximate.}. Furthermore, analytical results allow us to (at least roughly) quantify the approximation error for any given the number of realizations---and therefore the number of realizations needed to reach a given accuracy. On top of these theoretical assurances, the other big advantage of this approach is its simplicity: once the graph weights are realized, we only need to perform sums and maximizations of scalar values, rather than possibly dependent RVs.  
% Canon reference in support of the convergence claim? 

The major disadvantage of MC methods is the computational cost. Of course, modern architectures are well-suited to this approach because of their parallelism, but MC can still be impractical for large, dense graphs that require many realizations in order to obtain an accurate solution. For this reason, in our numerical experiments we typically only use MC to obtain a reference solution for the longest path distribution of a given schedule graph. 
% We call it a heuristic since the solutions are not exact by definition, although we do use them as a reference since they are guaranteed to converge...


\subsection{Applying the CLT}
\label{subsect.normality}

Fundamentally, the length of any given path through a schedule graph is just the sum of the weight RVs along it. By the Central Limit Theorem (CLT), sums of random variables are asymptotically normally distributed. So we can make a reasonable argument that the longest path distribution itself is likely to be at least approximately normal, $L_n \approx N(\mu_n, \sigma_n)$. Indeed, this has often been observed empirically, even when the graph weights follow distributions that are far from normal \cite{can10}. This argument forms the basis of a family of efficient heuristics for computing an approximation to the longest path distribution.

\subsubsection{Clark's equations and Sculli's method}
\label{subsubsect.clark_sculli}

Computing the longest path ultimately reduces to performing summations and maximizations of dependent random variables. If we assume that all weight RVs can be characterized by their mean and variance (i.e., effectively that they are also normal), then sums can be computed though the well-known rule for any two normal RVs $\epsilon \sim N(\mu_\epsilon, \sigma_\epsilon^2)$ and $\eta \sim N(\mu_\eta, \sigma_\eta^2)$,
\begin{align}
\label{eq.sum_moments}
\epsilon + \eta \sim N \big(\mu_\epsilon + \mu_\eta, \sigma_\epsilon^2 + \sigma_\eta^2 + 2 \rho_{\epsilon\eta}\sigma_\epsilon \sigma_\eta \big), 
\end{align}
where $\rho_{\epsilon\eta}$ is the linear correlation coefficient between the two distributions. Formulae for the first two moments of the maximization of two normal RVs---which is not itself normal---are less well-known but were first provided by Clark in the early 1960s \cite{cla61}. Let 
\begin{align*}
\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \quad \text{and} \quad \Phi(x) = \int_{-\infty}^{x} \phi(t) dt
\end{align*}
be the unit normal probability density function and cumulative probability function, respectively, and define 
\begin{align}
  \label{eq.alpha_beta}
\alpha = \sqrt{\sigma_\epsilon^2 + \sigma_\eta^2 - 2 \rho_{\epsilon\eta}\sigma_\epsilon \sigma_\eta} \quad \text{and} \quad \beta = \frac{\mu_\epsilon - \mu_\eta}{\alpha}. 
\end{align}
Then the first two moments $\mu_{\max}$ and $\sigma_{\max}$ of $\max(\epsilon, \eta)$ are given by
\begin{align}
\mu_{\max} &= \mu_\epsilon \Phi(\beta) + \mu_\eta \Phi(-\beta) + \alpha \phi(\beta), \label{eq.clark_max_mu}\\
\sigma_{\max}^2 &= (\mu_\epsilon^2 + \sigma_\epsilon^2) \Phi(\beta) + (\mu_\eta^2 + \sigma_\eta^2) \Phi(-\beta) \label{eq.clark_max_sigma}\\
&+ (\mu_\epsilon + \mu_\eta)\alpha\phi(\beta) -\mu_{\max}^2 \nonumber.
\end{align}
Although these formulae are exact, they are only valid for a single pair of normal RVs. As already noted, the maximization of two normal RVs is not normal, so we cannot obtain the exact moments for a set of arbitrarily many RVs by applying them in a pairwise manner. However, we can at least get an approximation. Sinha, Zhou and Shenoy \cite{sin07} empirically investigated the accuracy of this approximation for sets of up to 100 normal RVs, concluding that it is usually fairly good. Furthermore, they considered several possible orderings for the operands of the maximization (randomly, by mean value, and so on), a topic that was also briefly discussed by Ross \cite{ross03}.        

Bringing this all together, by using \eqref{eq.sum_moments} for summations, and \eqref{eq.clark_max_mu} and \eqref{eq.clark_max_sigma} pairwise for maximizations, we can now move through the graph in a manner similar to \eqref{eq.Li} and compute approximations $\mu_n$ and $\sigma_n^2$ to the first two moments of the longest path which, since it is assumed to be roughly normal, suffices to describe the entire distribution. This method appears to have first been proposed for estimating the completion time of PERT networks by Sculli \cite{scu83}, although to simplify the problem he assumed that all of the correlation coefficients $\rho_{\epsilon \eta}$ in \eqref{eq.alpha_beta} were zero (see next section).

In practice, the moment estimates obtained using Sculli's method tend to be quite accurate, with performance improving as the weight distributions move closer to normality and the number of nodes in the graph increases (as we might intuitively expect). More importantly, Sculli's method is typically much faster than the alternatives \cite{can16}. 

\subsubsection{Including correlations}
\label{subsubsect.correlation_aware}

Sculli assumed that all correlations were zero, which is rarely the case in practice since common ancestors make the longest path at two nodes dependent, even if all weights themselves are independent. Computing the correlation coefficients efficiently is tricky. However, Canon and Jeannot \cite{can16} proposed two different heuristics which alternatively prioritize precision and speed. The first is a dynamic programming algorithm called Cordyn which recursively computes the correlations using formulae derived in Clark's original paper for the correlation coefficients between any normal RV $\tau$ and a summation or maximization of normal RVs $\epsilon$ and $\eta$, 
\begin{align*}
  \rho_{\tau, \, \text{sum}(\epsilon, \eta)} &= \frac{\sigma_\epsilon \rho_{\tau \epsilon} + \sigma_\eta \rho_{\tau \eta} }{\sigma_{\text{sum}}} \quad \text{and} \quad
\rho_{\tau, \max(\epsilon, \eta)} = \frac{\sigma_\epsilon \rho_{\tau \epsilon} \Phi(\beta) + \sigma_\eta \rho_{\tau \eta} \Phi(-\beta)}{\sigma_{\max}}.
\end{align*} 
Cordyn has time complexity $O(ne) \approx O(n^3)$, so is more expensive than Sculli's method, which is quadratic in $n$, but numerical experiments performed by Canon and Jeannot suggest that it is almost always more accurate. 
% something about being competitive with reduction based methods?

In an effort to marry the speed of Sculli's method and the accuracy of Cordyn, Canon and Jeannot also proposed an alternative heuristic called CorLCA. The main idea is to construct a simplified version of the DAG called a {\em correlation tree} that has all the same nodes as the original but only retains a subset of the edges. In particular, where multiple edges are incident to a node---i.e., a maximization must be performed---only the edge which contributes most to the maximization is retained in the correlation tree. The motivation here is that the correlation coefficient between any two longest path estimates $L_i$ and $L_k$ can be efficiently approximated by finding the {\em lowest common ancestor} (LCA) $t_{a}$ of the corresponding nodes $t_i$ and $t_k$ in the correlation tree: since $L_i \approx L_a + \eta$ and $L_k \approx L_a + \epsilon$ where $\eta$ and $\epsilon$ are independent RVs representing the sums of the costs along the paths between $t_a$ and $t_i$ (resp. $t_a$ and $t_k$) in the correlation tree, we have
\begin{align*}
  \rho_{L_i, L_k} \approx \frac{\sigma_{L_a}^2}{\sigma_{L_i}\sigma_{L_k}}. % Not technically correct---introduce C?
  \end{align*}
  For every edge, we need to do a lowest common ancestor query, so the time complexity of CorLCA depends to a large extent on the cost of these. Although they do not present a method, based on similar results in the literature, Canon and Jeannot hypothesize this can be done in $O(1)$ operations, giving an overall time complexity $O(e) \approx O(n^2)$ for the entire algorithm. At any rate, an extensive numerical comparison of several heuristic methods for approximating the longest path distribution by the original authors suggested that CorLCA is more efficient than Cordyn with only a relatively small reduction in accuracy \cite{can16}. It should however also be noted that it can do badly when longest path length estimates at two or more nodes with a common child are similar since only one of the respective edges to the child will be retained in the correlation tree.

  \subsubsection{The canonical method}
\label{subsubsect.canonical}


Another method for estimating the longest path distribution that approximates correlations in a similar manner comes from the field of digital circuit design. In the so-called {\em canonical model} \cite{vis06,zha06}, all RVs are expressed as the sum of their expected value and a weighted sum of standard normal distributions that characterize the variance, 
\begin{align*}
\eta = \mu + \sum_i v_i \delta_i,
\end{align*}  
where all $\delta_i \sim N(0, 1)$ and are independent of one another. The advantage of this is that evaluating summations and maximizations becomes much more straightforward. Let $\eta = \mu_\eta + \sum_i v_{\eta, i} \delta_i$ and $\epsilon = \mu_\epsilon + \sum_i v_{\epsilon, i} \delta_i$. Then 
\begin{align*}
\omega = \eta + \epsilon = (\mu_\eta + \mu_\epsilon) + \sum_i (v_{\eta, i} + v_{\epsilon, i}) \delta_i.
\end{align*}
Suppose now that $\omega = \max(\eta, \epsilon)$. Let $\alpha$ and $\beta$ be defined as in \eqref{eq.alpha_beta}, and $\Phi(x) = \int_{-\infty}^{x} \phi(t) dt$ be the standard normal cdf. Note that computing $\beta$ requires the linear correlation coefficient $\rho_{\eta\epsilon}$ which can be efficiently calculated as:
\begin{align*}
\rho_{\eta\epsilon} = \frac{\sum_i v_{\eta, i} v_{\epsilon, i}}{\sqrt{\sum_i v_{\eta, i}^2} \cdot \sqrt{\sum_i v_{\epsilon, i}^2} }.
\end{align*}
By definition, $\P[\eta > \epsilon] = \Phi(\beta)$ and we can therefore approximate $\omega$ by 
\begin{align*}
\hat{\omega} &= \Phi(\beta)\eta + \Phi(-\beta) \\
&= \Phi(\beta) \mu_\epsilon + \Phi(-\beta) \mu_\epsilon + \sum_i \big( \Phi(\beta) v_{\eta, i} + \Phi(-\beta) v_{\epsilon, i} \big) \delta_i.
\end{align*}
This is both similar and in some sense contrary to the Clark equation approach, in that the latter precisely computes the first two moments of the maximization of two normal RVs, whereas the canonical method approximates the distribution of the maximization of any two RVs using linear combinations of normal RVs. In their empirical comparison, Canon and Jeannot found that the canonical method tended to fall between Sculli's heuristic and CorLCA in terms of both speed and approximation quality \cite{can16}, so we decided not to include it in comparisons here. 


\subsubsection{Kamburowski's bounds}
\label{subsubsect.kamburowski}

As stated in Section \ref{sect.bounds}, when all costs are independent Gaussian RVs, Kamburowski was able to prove both upper and lower bounds on the first two moments\footnote{As noted previously, the upper bound on the variance technically remains a conjecture.} of the longest path distribution. Since the bounds are somewhat similar to the approaches discussed elsewhere in this section, we describe them here.

The basic idea is to recursively compute four number sequences $\underline{m_i}$, $\overline{m_i}$, $\underline{s_i}$ and  $\overline{s_i}$ such that $\underline{m_i} \leq \mu_{L_i} \leq \overline{m_i}$ and $ \underline{s_i} \leq \sigma_{L_i} \leq \overline{s_i}$ for all $i = 1, \dots, n$. Clearly, by taking $\underline{m_1} = \overline{m_1} = \E[\pi_1]$ and $\underline{s_1}^2 = \overline{s_1}^2 = Var[\pi_1]$ we can achieve the desired bounds for $L_1$. (As ever, we could work backward instead, in which case the analogous results hold for the index $n$.) Now we suppose that all of the upper and lower bounds have been computed for all of the parents of a given node $t_i$ and consider how we can construct  $\underline{m_i}$, $\overline{m_i}$, $\underline{s_i}$ and  $\overline{s_i}$. The variance bounds are relatively straightforward, albeit loose. The lower bound is given by
\begin{equation}
\underline{s_i^2} =\left\{
\begin{array}{@{}ll@{}}
\underline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}], \quad  \text{if $P_i = \{s_h\}$,} \\
0,  \quad \text{ otherwise},
\end{array}\right.
\label{eq.si_under}
\end{equation}
reflecting the intuition that the variance can be reduced almost arbitrarily by a maximization (which needs to be performed for the case of multiple parents). The upper bound is similarly intuitive since it is effectively equivalent to saying that the variance of the maximum of a set of normal RVs is bounded above by the maximum variance of the RVs, although this has never been proven (see Section \ref{subsubsect.perspective}). More precisely, define 
\begin{align}
  \label{eq.si_over}
  \overline{s_i^2} = \max_{h \in P_i}\{ \overline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]\}.
\end{align}
The bounds on the expected value are somewhat more complex. First, define a function $h$ by
\begin{align*}
  h(\mu_i, \sigma_i, \mu_k, \sigma_k) = \mu_i \Phi(\overline{\beta}) + \mu_k \Phi(-\overline{\beta}) + \overline{\alpha} \phi(\overline{\beta}),
\end{align*}
where $\overline{\alpha} = \sqrt{\sigma_i^2 + \sigma_k^2}$ and $\beta = (\mu_i - \mu_k)/ \overline{\alpha}$. Per equation \eqref{eq.clark_max_mu}, $h$ is the expected value of the maximization of two {\em independent} normally distributed RVs $X_i \sim N(\mu_i, \sigma_i^2)$ and $X_k \sim N(\mu_k, \sigma_k^2)$. Now, suppose that we have a set of (not necessarily independent) normally distributed RVs $X_1, X_2, \dots, X_r$, where each $X_i \sim N(\mu_i, \sigma_i^2)$ and $\sigma_1 \leq \sigma_2 \leq \dots \leq \sigma_r$. Define two functions $\underline{f}$ and $\overline{f}$ by the recursions,
\begin{align*}
  &\underline{f}(X_1) = \overline{f}(X_1) = \mu_1, \\
  &\underline{f}(X_1, X_2) = \overline{f}(X_1, X_2) = h(\mu_1, \sigma_1, \mu_2, \sigma_2), \\
  &\underline{f}(X_1, \dots, X_r) = h(\underline{f}(X_1, \dots, X_{r - 1}), 0, \mu_r, \sigma_r), \\
  &\overline{f}(X_1, \dots, X_r) = h(\overline{f}(X_1, \dots, X_{r - 1}), \sigma_{r - 1}, \mu_r, \sigma_r).
\end{align*}
Then, for all $i = 2, \dots, n$, if we define
\begin{align*}
  \underline{m_i} &= \underline{f}(\{ \underline{X_h} \}_{h \in S_i}),
\end{align*}
where
\begin{align*}
  \underline{X_h} &\sim N(\underline{m_h} + \E[\pi_{hi}] + \E[\pi_{i}], \; \underline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]),
\end{align*}
and
\begin{align*}
  \overline{m_i} &= \overline{f}(\{\overline{X_h}\}_{h \in S_i}),
\end{align*}
where
\begin{align*}
  \overline{X_h} \sim N(\overline{m_h} + \E[\pi_{hi}] + \E[\pi_{i}], \; \overline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]),
  \end{align*}
we have 
\begin{align*}
  \underline{m_i} \leq \mu_{L_i} \leq \overline{m_i}.
\end{align*}
(Here we are assuming that the sets $\{\underline{X_h}\}_{h \in S_i}$ and $\{\overline{X_h}\}_{h \in S_i}$ are ordered in such a way that the inequality constraints on the variances is satisfied.)

\subsubsection{A path-centric perspective}
\label{subsubsect.perspective}

From first principles, the longest path through a graph is exactly that: the longest of all possible paths. Let $q$ denote the number of paths through a given schedule graph and $P_a$, $a \in \{ 1, \dots, q \}$, be any path through the DAG. Then by definition we of course have
\begin{align}
  \label{eq.first_principles}
  L_n = \max_{a = 1, \dots, q} P_a.
  \end{align}
  The obvious problem with this method of computing the longest path is that $q$ is (usually) impractically large for even small graphs, so the dynamic programming approach defined by \eqref{eq.Li} is (usually) the only practical option. Hence \eqref{eq.first_principles} would seem to be of very little use in bounding or even approximating the longest path. However, by making use of the normality assumption induced by the CLT, we may still be able to derive useful approximations to the longest path distribution. 

  Since all paths are approximately normal---or exactly normal if all weight distributions are as well---we assume from now on that equation \eqref{eq.first_principles} reduces to the problem of finding the maximum of a (very large) set of dependent, differently distributed (DDD) normal RVs. Although much less studied than the IID case, bounds on both the distribution and its moments have received some attention in the literature. However, few of these are practical for very large sets. Ross gives a general upper bound for the expected value of a set of (not necessarily normal) DDD RVs, which he later specializes for the normal case, as well as mathematical programs for computing tight upper and lower bounds when the RVs are normally distributed \cite{ross03}. Unfortunately, all of these bounds require iterating over the set of paths at some point or other and their practical limit is stated to probably be for sets comprising hundreds of RVs. Similarly, efficiently computing the distribution bounds of Galambos \cite{gal72} seems impossible.

  Now, there are certain quantities of possible interest that we can compute directly even when $q$ is very large. For example, if all weights are normal, then the mean of a given path length is just the sum of the means of the weights along it, so we can easily compute $\max_a(\E[P_a])$ via dynamic programming. This is useful because by Jensen's inequality we have  
$\E[\max_aP_a] \geq \max_a(\E[P_a])$---i.e., the classic CPM lower bound on the expected value of the longest path. (Of course, this can be proven via other methods to be true even when all weights are not normally distributed.) Similarly, $\max_a(Var[P_a])$ can be computed cheaply for normal weights; this is Kamburowski's conjectured upper bound on the variance of the longest path in that case. Indeed, the bound therefore holds if and only if the variance of the maximum of a set of normals is smaller than the maximum variance of the individual RVs. Counterexamples can easily be found for arbitrary RVs, but empirically this seems as though it may be true for normal RVs... In fact, if we assume that the shape of the maximum is roughly normal, we could argue heuristically that the variance is bounded by the variance of the path which maximizes $\mu_a + \sigma_a$...   



  The only practical way forward is to reduce the number of paths we need to consider. Of course, it is impossible to do this entirely accurately. However, note that we can compute the correlations between any two paths, as well as the probability that one is greater than another. The plan then: generate paths until the probability it is the longest goes below some tolerance and then we will have a much smaller sets of path lengths to deal with... This is similar to Dodin's method... Also done by Ludwig, inspired by earlier work of Spelde... 




  
% QUESTION FOR NEIL.
  %Perhaps the best approach is to give up on exact bounds and take a heuristic approach. In particular, the following concentration inequality may be useful for (roughly) bounding the distribution function of the longest path...
  %\begin{prop}
%	Let $g = (g_1, \dots, g_n)$ be a Gaussian random vector, whose coordinates are not necessarily independent. One can express $g$ as... Let $\sigma^2 = \max_iVar(g_i)$. Then for all $t > 0$,
%	\begin{align*}
%	\P\bigg[\max_i g_i - \E[\max_i g_i] \geq t \bigg] \leq e^{-t^2/2\sigma^2}
%	\end{align*}
     %   and
     %   \begin{align*}
%	\P\bigg[\max_i g_i - \E[\max_i g_i] \leq -t \bigg] \leq e^{-t^2/2\sigma^2}.
%	\end{align*}
    %  \end{prop}

      


% Spelde's heuristic bound.

% One speculative approach that might be useful is to consider extreme value theory... The problem is that it isn't clear how to characterize the distribution. Paper by Berman (and other one) seems to suggest that max of dependent normals will also tend to Gumbel but don't know anything about the correlations...
%Similarly, although correlations between any two given paths can easily be computed (exactly in the normal weight case, or approximately otherwise) in a manner very similar to how they are estimated in the CorLCA heuristic by separating the path lengths into sums of shared and unique weight RVs, explicitly computing the correlations between all pairs of paths is not possible. 



\section{Updating makespan estimates}
\label{sect.updating}

% TODO: rewrite all this, no longer using this approach (see slides for viva presentation). "A big advantage of the correlation based approach is that we can quickly update the makespan/longest path estimate in response to realized data..."
% Mention emapse somewhere - e.g., we don't repeat the work of Canon, who did the best empirical comparison of different methods for computing the longest path distribution... Many of the methods discussed here were implemented in their emapse package... We chose to implement our own smaller-scale simulator for continuity with earlier work in this thesis...
% This is a question that is particularly relevant when large, unexpected delays occur and decisions may need to be made as to whether to continue following the computed schedule at all.

Estimating the length of a schedule with stochastic costs before its execution has been widely-studied, as the examples in previous sections illustrate. We therefore focus here on a different but related problem: how can schedule makespan estimates be quickly updated {\em during} execution? This would be particularly useful in situations such as when a large unexpected delay occurs. More precisely, the scenario we consider is as follows. Given a schedule $\pi$, we computed a complete set of task finish times estimates $L_i \sim N(\mu_i, \sigma_i^2)$ for all $i = 1, \dots, n$ before runtime using one of the Clark equation-based methods discussed in Section. At some point in time $T$ during the schedule execution we want to compute a new, more accurate estimate of the makespan based on the costs which have been observed thus far. How do we do this as quickly and accurately as possible?

Effectively, at time $T$ the schedule graph $G_s$ can be divided into two distinct subgraphs: one corresponding to those tasks that have been completed and the other to those that have not. Define $C_T$ to be the set of indices corresponding to tasks that have completed by time $T$ and $U_T$ to be the set of indices corresponding to tasks that are still not done. Furthermore, define $C_T^* \subseteq C_T$ to be the set of indices of tasks which have been completed but at least one of their parents has not---i.e., in some sense the boundary of the realized and unrealized sections of the graph.
% something about the first having multiple exit tasks and the second multiple entry tasks?

Since all cost RVs corresponding to tasks indexed by $C_T$---and the edges between them---have been realized, we can compute the realized finish times $\ell_i$ for the corresponding tasks in the usual manner for scalar costs. The question then remains of how we compute an updated set of longest path estimates $L_k'$ for all $k \in U_T$, including a new final makespan estimate $L_n'$. We outline different possible approaches to this problem in the following three sections.

\subsection{Estimating the remaining time}
\label{subsect.remaining}

The most straightforward approach is to simply consider the unrealized portion of the graph separately and compute the longest path through it, starting from any of the boundary tasks indexed by $C_T^*$, using any heuristic method; a new longest path estimate which passes through the given boundary task is then the sum of the realized longest path up to and including the task, plus the estimated longest path through the remaining unrealized subgraph. More efficiently, rather than initially computing values $L_i$ that represent longest path lengths from the source to a task (inclusive), we can compute a sequences of values $R_i$ that represent the longest paths from the tasks to the sink (exclusive)---i.e., estimates of the remaining time until the entire schedule has been completed. In particular, we set $R_n = 0$, then work backward and recursively compute  
\begin{align*}
  R_i = \max_{k \in S_i} \{ \pi_{ik} + \pi_k + R_k  \}
\end{align*}
for all other tasks, where the moments of the maximization are computed using the Clark formulae in a manner corresponding to whichever of Sculli's method, CorLCA or CorDyn we decide to use. Note that since the $R_i$ do not include the cost of task $t_i$ the full schedule makespan estimate is $R_1 + \pi_1$.

(Minor changes need to be made to CorLCA and CorDyn in order to estimate the correlations when working backward through the DAG. For example, in CorLCA, rather than the lowest common ancestors of two tasks, we want the deepest common descendants. However these changes are fairly straightforward. As an aside though, fairly significant differences are sometimes apparent between the makespan moment estimates computed forward and backward through the DAG for all three heuristics, particularly with regard to the variance. For example, we found that for Cholesky schedule DAGs, the variance was always smaller when the makespan is computed backward. We attribute this to the fact that the average number of task children exceeds the average number of task parents so the corresponding maximizations contain more terms; since these are computed pairwise and the effect of \eqref{eq.clark_max_sigma} is to decrease the variance, this may not be entirely surprising.) 

The advantage of this approach is that at time $T$ the estimated longest path which passes through task $t_i$, where $i \in C_T^*$, is simply given by $L_i' = \ell_i + R_i$ and, in particular, a new estimate of the makespan can be computed through
\begin{align*}
  L_n' = \max_{i \in C_T^*} \{ \ell_i + R_i  \}.
  \end{align*}
This maximization can be done in the same manner as the calculation of the $R_i$, using the same set of correlation coefficients (or not, if using Sculli's method).

\subsection{Updating the makespan directly}
\label{subsect.corr_update}

Another possible method for updating the final makespan estimate makes use of the following result.
\begin{prop}
	Let $u$ be a normally distributed vector with mean $\bar{\mu}$ and covariance $\Sigma_u$, $u \sim N(\bar{\mu}, \Sigma_u)$, and suppose that $u = (v, w)$. Then 
	\begin{align*}
	(w \mid v) \sim N \big( \bar{w} + \Sigma_{wv}\Sigma_{vv}^{-1} (v - \bar{v}), \enspace  \Sigma_{ww} - \Sigma_{wv} \Sigma_{vv}^{-1} \Sigma_{vw} \big).
	\end{align*}
\end{prop}
Note that if all of the linear correlation coefficients $\rho_{uv}$ are known, we can use the definition $\rho_{uv} = \Sigma_{uv} / \sigma_u \sigma_v$ to find $\Sigma_{uv}$.

This proposition is useful because we have been implicitly assuming that there is a joint normal distribution across the entire set of finish times $L_i$ due to their dependencies. Furthermore, we can estimate the correlation coefficients between finish times at any two tasks using, for example, the correlation tree approach of CorLCA. This means that we can update the final makespan estimate using only the observed finish times of the tasks indexed by $C_T^*$. For compactness of notation let $\rho_{in} = \rho_{ni}$ be the linear correlation coefficient between $L_i$ and $L_n$. Suppose that task $t_i$ has finished at time $\ell_i$. Then we can compute a new estimate $L_n^i$ of the final makespan by applying the above result as follows,
\begin{align*}
L_n^i &\sim N \bigg( \mu_{n} + \frac{\rho_{ni} \sigma_{n} \sigma_{i}}{\sigma_{i}^2} (\ell_i - \mu_{i}), \enspace \sigma_{n}^2 - \frac{\rho_{ni} \sigma_{n} \sigma_{i} \cdot \rho_{in} \sigma_{i} \sigma_{n}}{\sigma_{i}^2} \bigg) \nonumber\\
&\sim N \bigg(\mu_{n} + \frac{\rho_{ni} \sigma_{n}}{\sigma_{i}} (\ell_i - \mu_{i}), \enspace (1 - \rho_{ni}^2) \sigma_{n}^2 \bigg).
\end{align*}
We do this for all $i \in C_T^*$ and then compute their maximum (using the same method as before to estimate the correlation coefficients, if they are not already known) in order to obtain a new estimated final makespan $L_n'$, 
\begin{align*}
  L_n' = \max_{i \in C_T^*} \{ L_n^i  \}.
  \end{align*}

\subsection{Propagating updates forward}
\label{subsect.propagating}

Rather than updating the finish time of the exit task---and therefore the makespan---directly, we can instead move forward through the DAG and update the finish time estimates for all unrealized tasks. This is slightly more expensive of course but potentially more accurate. Now, in principle the updated finish times can be computed for each task $t_i$, where $i \in U_T$, using equation \eqref{eq.Li} in the usual manner. However, there are essentially three different cases that we need to consider, depending on the status of the terms in the maximization.
\begin{enumerate}
\item Both $\pi_{hi}$ and $L_h$ have been realized for all $h \in P_i$.
\item Both $\pi_{hi}$ and $L_h$ have been realized for some $h \in P_i$ but not others. 
  \item Both $\pi_{hi}$ and $L_h$ have been realized for none of the parents.
  \end{enumerate}
  In the first instance, the sums of $\pi_{hi}$ and $L_h$ are now deterministic so the maximization is just done over a set of scalars and is therefore straightforward. Similarly, in the third case, all of the sums are unrealized RVs so we can just use Clark's equations again to compute the new finish time estimate.

The second case is more interesting. The problem basically reduces to how we compute the maximum of a set of RVs, some of which have been realized and others which have not. For notational ease, let $Z_h = \pi_{hi} + L_h$ and $M_i = \max_{h \in P_i} \{ Z_h  \}$.  Let $X_i$ be the maximum over the subset of parents for which $Z_h$ has been realized. Now, we know that $M_i > X_i$ since at least some of the $Z_h$ have not been realized yet. Furthermore, we have already computed an estimate of $L_i = \pi_i + M_i$, where $M_i$ is assumed to be roughly normal, so we can also explicitly form $M_i \sim N(\mu_{M_i}, \sigma_{M_i}^2)$. We want to find a new finish time estimate
\begin{align}
  \label{eq.dash_Li}
  L_i' = \pi_i + (M_i | M_i > X_i). 
\end{align}
Given that $M_i$ is assumed to be Gaussian, we can model the term on the right as a truncated Gaussian. Let $a = (X_i - \mu_{M_i}) / \sigma_{M_i}$ and $b = 1 - \Phi(a)$, where $\Phi$ is the unit normal cdf as before. Then the first two moments of $(M_i | M_i > X_i)$ are given by
\begin{align*}
  \E[M_i \mid M_i > X_i] = \mu_{M_i} + \frac{\sigma_{M_i}\phi(a)}{b}
\end{align*}
and
\begin{align*}
  Var[M_i \mid M_i > X_i] = \sigma_{M_i}^2 \bigg[ 1 + \frac{a\phi(a)}{b} - \bigg( \frac{\phi(a)}{b} \bigg)^2    \bigg].
\end{align*}
Using these expressions, we can now compute \eqref{eq.dash_Li}, and therefore work through the remainder of the DAG updating the finish time estimates for all tasks that have not yet completed. 

\section{Numerical experiments}
\label{sect.results}

In order to study the problem of estimating the longest path of a stochastic graph---i.e., the makespan distribution of stochastic schedules---we created a simple software package which implements several of the heuristic methods discussed so far in this chapter. As in previous chapters, the source code is written in {\tt Python} and is available in its entirety on Github\footnote{\href{https://github.com/mcsweeney90/stochastic-longest-path}{{\tt \small https://github.com/mcsweeney90/stochastic-longest-path}}}. Much more sophisticated software along these lines already exists, such as the {\em Emapse} package from Canon and Jeannot (citation). However, we decided to create our own, both as a learning exercise and for ease of integration with other work in this thesis. In this section, we describe the results of small-scale numerical experiments performed in this framework concerning various aspects of the longest path estimation problem.

\subsection{Before runtime}
\label{subsect.before_runtime}

Exhaustive comparisons of heuristic methods for estimating the longest path distribution before any RVs have been realized have been done before in the literature, with the best example again probably being the work of Canon and Jeannot \cite{can16}. Rather than repeating those investigations, we take a narrower view and focus on a single family of graphs based on schedules for a widely-used application in scientific computing, namely Cholesky factorization, on an accelerated target platform.

More specifically, the graphs are constructed from schedules computed by the static HEFT heuristic for Cholesky task graphs with between $35$ and $11480$ tasks (corresponding to matrix tilings from $5 \times 5$ to $40 \times 40$, with the dimensions increasing in increments of $5$). The target platform is the {\em Single GPU} platform from Chapter X, comprising 7 CPU resources and one GPU. The schedule is initially computed as in Chapter X, which then determines the topology of the schedule graph---i.e., where we add the disjunctive edges to the original task graph. The node and edge weights of the schedule graph are then modeled as random variables with means and variances given by the sample means and variances we observed for the relevant tasks in the experimental testing we described in Chapter X, with tile size $128$ and no asynchronous data transfers being assumed.

Taking the main conclusions of the more wide-ranging study by Canon and Jeannot as given, at least in the general case, the overall aim of our small-scale investigation is basically to determine whether the improved moment estimates produced by the correlation-aware heuristic CorLCA rather than Sculli's method are worth the extra computational cost for the realistic example schedule graphs considered here. In addition, we also briefly consider how useful some of the cheaper bounds are in this case, with a view to their possible use for making scheduling decisions.

\subsubsection{The normality assumption}
\label{subsubsect.results_normality}

Other studies have thoroughly investigated how close to normal the longest path distribution actually tends to be for randomly-generated schedule DAGs, so we only treat this topic very briefly here. Our conclusions for the Cholesky schedule graphs are that the longest path distribution does very much tend to normality as the number of tasks increases and the costs themselves are sampled from distributions closer to normal.

In order to estimate the true longest path distribution in this section---and the following two---we use the Monte Carlo method with $10^5$ samples. Given the number of samples, these estimates are likely to be very good for the smallest graphs but perhaps slightly less accurate for the largest ones (although we expect them to still be at least fairly good).

First we assume that all individual costs are normally distributed. Now, there are several standard statistical tests for normality, such as Shapiro-Wilks, Anderson-Darling or Kolmogorov-Smirnoff, etc, but it is perhaps more instructive here to consider the longest path distribution visually. Figure X shows how the shape of empirical distribution changes as the number of tasks in the DAG increases... We see that the distribution does indeed more closely resemble the normal bell curve as the size of the DAG increases...

\begin{figure}
	\centering	
	\includegraphics[scale=1.0]{normality_placeholder.png}
	\caption{Placeholder--TODO.}	
	\label{plot.normal_assum_normal}
      \end{figure}
      % TODO: just a placeholder, better image.

% TODO: Extend this - more analysis of the distribution itself.

\subsubsection{Kamburowski's bounds}
\label{subsubsect.results_bounds}

Although there are many bounds on the longest path distribution in the literature, given our overriding interest in practical scheduling methods and our experience in the previous chapter with Fulkerson's bounds on the expected value---which were impractically expensive even for relatively small graphs---we decided to eschew methods which require the evaluation of complex integrals. Similarly, bounds based on graphs reductions may be prohibitively expensive. Hence we decided to focus here on bounds that can be computed through simple numerical schemes, such as the classic PERT-CPM bound on the mean and Kamburowski's bounds on the first two moments (when costs are normally distributed). The latter does require the evaluation of the unit normal cdf, but this is a standard part of most good numerical software libraries, so can be computed efficiently.

Table \ref{tb.mean_bounds} shows how tight the PERT-CPM and Kamburowski bounds on the expected value are for the Cholesky graph set, where the reference solution is computed using the Monte Carlo method with $10^5$ samples under the assumption that all individual RVs are normally distributed (although it should also be noted that results were extremely similar when costs are Gamma distributed, see previous section). We see that the lower bounds are very tight, with Kamburowski only improving on PERT-CPM very slightly. This may be down to the topology and cost structure of the Cholesky graphs, which is relatively simple, although it should be noted that in general it is not the case that complex applications necessarily have complex task graphs. The upper bounds from Kamburowski are much looser, although even in the worst case no more than $19\%$ greater than the true value. 
% TODO: gamma costs.

\begin{table}
	\caption{Tightness of bounds on the expected value for Cholesky DAGs, as a percentage of the reference expected value.} 
	\begin{center}	
		\begin{tabular}{c c c c c c c c c}
                  \cmidrule{1-9}
                  & \multicolumn{8}{c}{DAG size} \\
                  \cmidrule{2-9}
			Bound & $35$ & $220$ & $680$ & $1540$ & $2925$ & $4960$ & $7770$ & $11480$\\
			\cmidrule{1-9}
			PERT-CPM & $99.5$ & $98.9$ & $98.5$ & $98.7$ & $99.2$ & $99.2$ & $99.4$ & $99.5$\\
                  K. (lower) & $99.9$ & $99.4$ & $98.9$ & $99.1$ & $99.4$ & $99.3$ & $99.5$ & $99.6$\\
                  K. (upper) & $100.9$ & $104.0$ & $110.3$ & $118.7$ & $116.6$ & $114.0$ & $112.4$ & $111.5$\\
			\bottomrule
		\end{tabular}
		\label{tb.mean_bounds}
	\end{center}	
      \end{table} 

      Unfortunately, the variance bounds given by Kamburowski's method are considerably looser in both directions, potentially to the extent of being impractical when making scheduling decisions. Figure \ref{plot.variance_bounds} illustrates how wide the bounds are for the Cholesky graphs... 

      \begin{figure}
	\centering	
	\includegraphics[scale=1.0]{variance_bounds.png}
	\caption{Kamburowski's bounds on the variance for the Cholesky graph set. Reference solution given by solid line.}	
	\label{plot.variance_bounds}
      \end{figure}

      % TODO: just a comment that results were very similar for Gamma costs?

% Probably the cheapest possible bound to compute is the PERT bound so that's the natural comparison...



\subsubsection{Do correlations need to be considered?}
\label{subsubsect.results_correlations}

The question we consider here is, although CorLCA generally obtains superior estimates of the makespan distribution, are these gains significant enough to be worthwhile in a scheduling heuristic?

\subsection{Updating the finish time}
\label{subsect.results_updating}

Consider different permutations (fraction of tasks initially realized, distributions of the costs, etc) in a systematic manner and compare with MC estimates... 

\section{Conclusions}
\label{sect.conclusions}

Conclusions go here. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{myplain2-doi}
\bibliography{references,strings}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
