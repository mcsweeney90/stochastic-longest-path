% !TeX document-id = {54177b55-cdde-488b-90fe-107922d59049}
\documentclass[12pt]{article}

\usepackage{a4} 
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[]{xcolor}
\usepackage{graphicx}
\usepackage[colorlinks,urlcolor=blue,linkcolor=blue,citecolor=hotpink]{hyperref}
\usepackage{booktabs}
\usepackage{rotating}
\usepackage{caption}
\usepackage[british]{babel}
\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage{epstopdf}
\usepackage{mathtools} % for :=
\usepackage{subfig}
\usepackage[most, minted]{tcolorbox}
\usepackage{mdwlist}
\tcbuselibrary{listings}

\newtcblisting{myminted}{%
	listing engine=minted,
	minted language=python,
	listing only,
	breakable,
	enhanced,
	minted options = {
		linenos, 
		breaklines=true, 
		breakanywhere, 
		fontsize=\footnotesize, 
		numbersep=2mm,
		tabsize=2
	},
	overlay={%
		\begin{tcbclipinterior}
			\fill[gray!25] (frame.south west) rectangle ([xshift=4mm]frame.north west);
		\end{tcbclipinterior}
	}   
}
\BeforeBeginEnvironment{minted}{\begin{tcolorbox}[breakable, enhanced]}%
	\AfterEndEnvironment{minted}{\end{tcolorbox}}%


\graphicspath{{images/}}

\title{Approximating the makespan distribution of stochastic schedules} % Think of a better title...
\author{Thomas McSweeney%
	\thanks{%
		School of Mathematics,
		University of Manchester,
		Manchester, M13 9PL, England
		(\texttt{thomas.mcsweeney@postgrad.manchester.ac.uk}).
	}
}
\date{\today}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\def\R{\mathbb{R}}
\def\C{\mathbb{C}}
\def\P{\mathbb{P}}
\def\E{\mathbb{E}}
\def\nbyn{n \times n}
\def\mbyn{m \times n}
\def\l{\lambda}
\def\norm#1{\|#1\|}      
\def\normi#1{\|#1\|_1}
\def\normo#1{\|#1\|_{\infty}}
\def\Chat{\widehat{C}}
\def\e{eigenvalue}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\argmin}{arg\,min}

% \DeclareMathOperator{\diag}{diag}   % Requires amsmath.
\def\diag{\mathop{\mathrm{diag}}}     % If not using amsmath.
\def\trace{\mathop{\mathrm{trace}}}   % If not using amsmath.

\def\At{\widetilde{A}}
\def\normt#1{\|#1\|_2}

% Set up lemma environment and its numbering.
\newtheorem{lemma}{Lemma}[section]

\def\proof{{\bf Proof}. \ignorespaces}
\def\qedsymbol{\vbox{\hrule\hbox{%
			\vrule height1.3ex\hskip0.8ex\vrule}\hrule}}
\def\endproof{\qquad\qedsymbol\medskip\par}

\newtheorem{theorem}{Theorem}
\newtheorem{prop}[theorem]{Proposition}

\allowdisplaybreaks[1]

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% For fine-tuning spacing in \sqrt etc=.  From \cite[p.~155]{knut99}.
% In math mode, @ will act as a macro that adds 1 unit of space.
% By comparison, \, skips 3mu.

\mathcode`@="8000 % Make @ behave as per catcode 13 (active).  TeXbook p. 155.
{\catcode`\@=\active\gdef@{\mkern1mu}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcounter{mylineno}
\makeatletter
\let\oldtabcr\@tabcr
\def\nonumberbreak{\oldtabcr\hspace{3.5pt}}
\def\mynewline{\refstepcounter{mylineno}%
	\llap{\footnotesize\arabic{mylineno}\hspace{5pt}}%
}
\def\lineref#1{\footnotesize\ref{#1}}
% Next macro adapted from latex.ltx
\gdef\@tabcr{\@stopline \@ifstar{\penalty%
		\@M \@xtabcr}\@xtabcr\mynewline}
\def\myvspace#1{\oldtabcr[#1]\mynewline}
\newenvironment{code}{%
	% Swap `:' and `colon'...
	\mathcode`\:="603A  % TeXbook pp 134, 154, 359 (top)
	% For original colon     \mathcode`\:="303A  % TeXbook p 344
	\def\colon{\mathchar"303A}
	\setcounter{mylineno}{0}
	\par
	\upshape
	\begin{list} % To give indentation
		{} {\leftmargin = 1cm}
		\item[]
		\begin{tabbing}
			
			% Default tab stops
			\hspace*{.3in} \= \hspace*{.3in} \=
			\hspace*{.3in} \= \hspace*{.3in} \= \kill
			\mynewline
		}{\end{tabbing}\end{list}}
\makeatother


\addto\captionsbritish{	\renewcommand{\bibname}%
	{References}%TODO: make sure reference style is consistent.
}

\definecolor{hotpink}{rgb}{0.9,0,0.5}

\begin{document}
	\maketitle 	


\section{Introduction}
\label{sect.intro}

% Questions for Neil: longest path or makespan throughout?

For any optimization problem, we obviously need to be able to evaluate how good any given solution is with regards to the optimization criteria in order to find an optimal, or otherwise acceptable, solution. The scheduling problems we consider here are clearly no exception: we want to know how good a computed schedule is, whether there are other schedules which are better, and so on. Evaluating the makespan of a given schedule would appear to be a straightforward problem---and so it is, when the computation and communication costs are static. But if costs are {\em stochastic} then this may no longer be the case.

Now, as long as it specifies the execution order of tasks on processors, any schedule $\pi$ for an application with task DAG $G$ can be represented by another DAG $G_{\pi}$ such that the longest path of $G_{\pi}$ is equal to the makespan of $\pi$: $G_\pi$ contains all the same vertices and edges as $G$, plus additional zero-weight {\em disjunctive} edges that indicate the execution order of the tasks on their chosen processors; the other weights of $G_\pi$ are induced by the processor selections of $\pi$. There's some flexibility in how we add the disjunctive edges; the most straightforward way to do it is to simply add an edge between a task $t_i$ and the task $t_h$ which is executed immediately before $t_i$ on its chosen processor if an edge does not already exist between the two. This can be done cheaply, although it should be noted that the related problem of adding the minimal number of necessary disjunctive edges is NP-hard [citation]. 
% Last bit sounds like it is true but can't find a reference...
% We can interpret the entire scheduling problem as a question of how to add disjunctive edges such that the longest path is minimized...

For example, consider the schedule $\pi$ from Figure X and the graph $G$ in Figure Y. We can construct the associated graph $G_\pi$ as shown in Figure Z. From now, we use the notations $\pi_i$ and $\pi_{ik}$ to represent the computation cost of task $t_i$ and the communication cost between tasks $t_i$ and $t_k$ under the schedule $\pi$, respectively. Assuming, without loss of generality, that there is only one entry task $t_1$ and one exit task $t_n$, to compute the longest path through $G_\pi$---and therefore the makespan of $\pi$---we compute a sequence of numbers $L_i$ defined by $L_1 = \pi_1$ and
\begin{align}
  \label{eq.Li}
  L_i = \pi_i + \max_{h \in P_i}\{ \pi_{hi} + L_h\}
\end{align}
for all other $i = 2, \dots, n$. The longest path of $G_\pi$ is then given by $L_n$. In the example above, we have... so we see that $L_n$ is indeed equal to the schedule makespan. Computing the longest path using \eqref{eq.Li} is an $O(n + e) \approx O(n^2)$ operation, which depending on the size of the DAG may be expensive but is at least polynomial. (Of course, we could work backward through the DAG by setting $L_n = \pi_n$ and doing the maximization over the set of task children in \eqref{eq.Li} instead; the makespan would then be given by $L_1$ but the procedure is otherwise equivalent.)

Unfortunately, in practice, schedule costs are almost never known precisely before runtime. Typically, the best we can do is estimate the probability distribution that we believe they follow based on previous executions of the application and its constituent tasks, or similar data---i.e., we model the costs as random variables (RVs). But if costs are RVs rather than fixed scalars, it is obviously impossible to specify the precise time at which each task should begin execution so at this point we need to redefine what we mean by a schedule: here, we assume that a schedule $\pi$ is a mapping from tasks to processors that specifies only which tasks each processor should execute and in what order; the processor then executes the next scheduled task as soon as it is able. Conceptually, we can view this as a processor being assigned an ordered queue of tasks before runtime and only being allowed to pop the task currently at the head of the queue. 

This definition means that even though costs are stochastic, the disjunctive graph $G_\pi$ has the same topology as it would in the static case. However, since all costs are RVs, the longest path is now also an RV and it is unclear how we should go about computing its distribution. If we attempt to apply \eqref{eq.Li} we soon run into difficulty because the $L_h$ may be dependent and computing the maximum of a set of dependent RVs is intractable in the general case. Indeed, Hagstrom \cite{hag88} proved that computing the longest path distribution, or even just its expected value, is a $\#P$-complete problem when all costs are discrete RVs, and there is no good reason to assume it is any easier for continuous RVs.      

Given the difficulty of the problem, bounds and approximations of the longest path distribution---and therefore the schedule makespan distribution---are typically needed instead. In this chapter, we describe several existing heuristic methods for doing this, before focusing on a related problem: how do we quickly update a longest path estimate---i.e., an estimated schedule makespan---at runtime? This is a question that is particularly relevant when large, unexpected delays occur and decisions may need to be made as to whether to continue following the computed schedule at all. Although useful on its own merits, in the context of this research this chapter functions as a bridge between earlier chapters which focus on computing schedules when costs are assumed to be known exactly and the later chapters in which the aim is to compute a schedule that is robust to the effects of uncertain cost estimates. We will see that many of the techniques discussed here underlie both existing stochastic scheduling heuristics and the new heuristic that we propose in the next chapter.   

The problem of approximating the distribution of the longest path through a DAG with stochastic weights occurs in contexts other than scheduling, such as {\em program evaluation review technique} (PERT) network analysis \cite{mal59} and digital circuit design \cite{bla08}. Hence in this chapter we use the more general terminology---i.e., {\em longest path} rather than {\em makespan}---but the choice of methods that we focus on is often motivated by our wider aim of computing the initial schedules for a given stochastic task graph.   
% better reference for digital circuit design? 

\section{Bounds}
\label{sect.bounds}

Although computing the exact distribution of the longest path distribution or its expected value is usually infeasible, bounds may be computed much more cheaply. Depending on the context, these may be tight enough to be useful. Now, while bounds on the distribution itself have been proven---for example, Kleindorfer gives both upper and lower bounds \cite{kle71}, the first of which was improved on by Dodin \cite{dod85}---these are typically based on graph reductions and fairly expensive, perhaps impractically so in the context of a scheduling heuristic, which is where our interest ultimately lies.
% Complexity results/more detail?

However, bounds on the expected value, or other moments, may be more practical. Indeed, we have already seen in the previous chapter that a lower bound $u_n$ on the expected value of $L_n$ (respectively $u_1$ and $L_1$ if working backward) can be computed in $O(n^2)$ operations by replacing all costs with their expected value and proceeding as in \eqref{eq.Li}---i.e., define $u_1 = \E[\pi_1]$ and
\begin{align}
  \label{eq.ui}
  u_i = \E[\pi_i] + \max_{h \in P_i}\{ \E[\pi_{hi}] + u_h\}
\end{align}
for all other $i = 2, \dots, n$, then we have $u_i \leq \E[L_i]$ and in particular $u_n \leq \E[L_n]$. Furthermore, we also saw that a tighter bound can be found through Fulkerson's \cite{ful62} alternative method, which was extended to continuous costs by Clingen \cite{cli64} and later improved by Elmaghraby \cite{elm67} and Robillard and Trahan \cite{rob76}.
% Repeat details here?

All of those methods provide only lower bounds for the expected value. If all costs are normally distributed RVs, then Kamburowski \cite{kam85} was able to prove both lower and upper bounds on the expected value, as well as a lower bound on the variance (and a conjectured upper bound). However, his method is conceptually very similar to the approach discussed in the following section, so will be presented in more detail there.

Rather than a formal bound, in many cases it may be more useful to simply approximate the longest path distribution (or its moments). To that end, many heuristic methods have been proposed. We focus in this chapter largely on the family of heuristics described in the following section, although alternative methods are briefly discussed in Section \ref{sect.other_methods}.


\section{Assuming normality}
\label{sect.normality}

Fundamentally, the longest path is computed through a series of summations and maximizations of the cost RVs. By the Central Limit Theorem, sums of random variables are asymptotically normally distributed so if we assume that the effect of the maximizations is minor, then the longest path distribution is likely to be approximately normal, $L_n \approx N(\mu_n, \sigma_n)$. Indeed, this has often been observed empirically, even when all costs follow very different distributions \cite{can10}. If we assume further that all RVs can be characterized by their mean and variance (i.e., effectively that they are also normal), then sums can be computed though the well-known rule for summing two normal RVs $\epsilon \sim N(\mu_\epsilon, \sigma_\epsilon^2)$ and $\eta \sim N(\mu_\eta, \sigma_\eta^2)$,
\begin{align}
\label{eq.sum_moments}
\epsilon + \eta \sim N \big(\mu_\epsilon + \mu_\eta, \sigma_\epsilon^2 + \sigma_\eta^2 + 2 \rho_{\epsilon\eta}\sigma_\epsilon \sigma_\eta \big), 
\end{align}
where $\rho_{\epsilon\eta}$ is the linear correlation coefficient between the two distributions. Formulae for the first two moments of the maximization of two normal RVs---which is not itself normal---are less well-known but were first provided by Clark in the early 1960s \cite{cla61}. Let 
\begin{align*}
\phi(x) = \frac{1}{\sqrt{2\pi}} e^{-x^2/2} \quad \text{and} \quad \Phi(x) = \int_{-\infty}^{x} \phi(t) dt
\end{align*}
be the unit normal probability density function and cumulative probability function, respectively, and define 
\begin{align}
  \label{eq.alpha_beta}
\alpha = \sqrt{\sigma_\epsilon^2 + \sigma_\eta^2 - 2 \rho_{\epsilon\eta}\sigma_\epsilon \sigma_\eta} \quad \text{and} \quad \beta = \frac{\mu_\epsilon - \mu_\eta}{\alpha}. 
\end{align}
Then the first two moments $\mu_{\max}$ and $\sigma_{\max}$ of $\max(\epsilon, \eta)$ are given by
\begin{align}
\mu_{\max} &= \mu_\epsilon \Phi(\beta) + \mu_\eta \Phi(-\beta) + \alpha \phi(\beta), \label{eq.clark_max_mu}\\
\sigma_{\max}^2 &= (\mu_\epsilon^2 + \sigma_\epsilon^2) \Phi(\beta) + (\mu_\eta^2 + \sigma_\eta^2) \Phi(-\beta) \label{eq.clark_max_sigma}\\
&+ (\mu_\epsilon + \mu_\eta)\alpha\phi(\beta) -\mu_{\max}^2 \nonumber.
\end{align}
Using \eqref{eq.sum_moments} for summations, and \eqref{eq.clark_max_mu} and \eqref{eq.clark_max_sigma} for maximizations, we can now move through the DAG and compute approximations $\mu_n$ and $\sigma_n$ (or $\mu_1$ and $\sigma_1$ if working backward) of the first two moments of the longest path distribution in a manner similar to \eqref{eq.Li}.

This method appears to have first been proposed for estimating the completion time of PERT networks by Sculli \cite{scu83}, although there he assumed that all of the correlation coefficients $\rho_{\epsilon \eta}$ in \eqref{eq.alpha_beta} were zero (see next section). While there are obviously no guarantees, the moment estimates obtained using Sculli's method tend to be fairly good \cite{kam85}, with performance improving as the cost distributions move closer to normality and the number of nodes in the graph increases, as we might expect. Furthermore, Sculli's method is typically much faster than the alternatives \cite{can16}. 

\subsection{Including correlations}
\label{subsect.correlation_aware}

Sculli assumed that all correlations were zero, which is rarely the case for real graphs since common ancestors make the longest path at two nodes dependent, even if all costs themselves are independent. Computing the correlation coefficients efficiently is tricky. However, Canon and Jeannot \cite{can16} proposed two different heuristics which alternatively prioritize precision and speed. The first is a dynamic programming algorithm called Cordyn which recursively computes the correlations using formulae derived in Clark's original paper for the correlation coefficients between any normal RV $\tau$ and a summation or maximization of normal RVs $\epsilon$ and $\eta$, 
\begin{align*}
  \rho_{\tau, \, \text{sum}(\epsilon, \eta)} &= \frac{\sigma_\epsilon \rho_{\tau \epsilon} + \sigma_\eta \rho_{\tau \eta} }{\sigma_{\text{sum}}} \quad \text{and} \quad
\rho_{\tau, \max(\epsilon, \eta)} = \frac{\sigma_\epsilon \rho_{\tau \epsilon} \Phi(\beta) + \sigma_\eta \rho_{\tau \eta} \Phi(-\beta)}{\sigma_{\max}}.
\end{align*} 
Cordyn has time complexity $O(ne) \approx O(n^3)$, so is more expensive than Sculli's method, which is quadratic in $n$, however numerical experiments by Canon and Jeannot suggest that it is almost always more accurate. 
% something about being competitive with reduction based methods?

In an effort to marry the speed of Sculli's method and the accuracy of Cordyn, Canon and Jeannot also proposed an alternative heuristic called CorLCA. The main idea is to construct a simplified version of the DAG called a {\em correlation tree} that has all the same nodes as the original but only retains a subset of the edges. In particular, where multiple edges are incident to a node---i.e., a maximization must be performed---only the edge which contributes most to the maximization is retained in the correlation tree. The motivation here is that the correlation coefficient between any two longest path estimates $L_i$ and $L_k$ can be efficiently approximated by finding the {\em lowest common ancestor} (LCA) $t_{a}$ of the corresponding nodes $t_i$ and $t_k$ in the correlation tree: since $L_i \approx L_a + \eta$ and $L_k \approx L_a + \epsilon$ where $\eta$ and $\epsilon$ are independent RVs representing the sums of the costs along the paths between $t_a$ and $t_i$ (resp. $t_a$ and $t_k$) in the correlation tree, we have
\begin{align*}
  \rho_{L_i, L_k} \approx \frac{\sigma_{L_a}^2}{\sigma_{L_i}\sigma_{L_k}}. % Not technically correct---introduce C?
  \end{align*}
For every edge, we need to do a lowest common ancestor query, so the time complexity of CorLCA depends to a large extent on the cost of these queries. Although they do not present a method, based on similar results in the literature, Canon and Jeannot hypothesize this can be done in $O(1)$ operations, giving an overall time complexity $O(e) \approx O(n^2)$ for the entire algorithm. At any rate, an extensive numerical comparison of several heuristic methods for approximating the longest path distribution by the original authors suggested that CorLCA is more efficient than Cordyn with only a relatively small reduction in accuracy \cite{can16}. It should however also be noted that it can do badly when longest path length estimates at two or more nodes with a common child are similar since only one of the respective edges to the child will be retained in the correlation tree.   


Another method for estimating the longest path distribution that approximates correlations in a similar manner comes from the field of digital circuit design. In the so-called {\em canonical model} \cite{vis06,zha06}, all RVs are expressed as the sum of their expected value and a weighted sum of standard normal distributions that characterize the variance, 
\begin{align*}
\eta = \mu + \sum_i v_i \delta_i,
\end{align*}  
where all $\delta_i \sim N(0, 1)$ and are independent of one another. The advantage of this is that evaluating summations and maximizations becomes much more straightforward. Let $\eta = \mu_\eta + \sum_i v_{\eta, i} \delta_i$ and $\epsilon = \mu_\epsilon + \sum_i v_{\epsilon, i} \delta_i$. Then 
\begin{align*}
\omega = \eta + \epsilon = (\mu_\eta + \mu_\epsilon) + \sum_i (v_{\eta, i} + v_{\epsilon, i}) \delta_i.
\end{align*}
Suppose now that $\omega = \max(\eta, \epsilon)$. Let $\alpha$ and $\beta$ be defined as in \eqref{eq.alpha_beta}, and $\Phi(x) = \int_{-\infty}^{x} \phi(t) dt$ be the standard normal cdf. Note that computing $\beta$ requires the linear correlation coefficient $\rho_{\eta\epsilon}$ which can be efficiently calculated as:
\begin{align*}
\rho_{\eta\epsilon} = \frac{\sum_i v_{\eta, i} v_{\epsilon, i}}{\sqrt{\sum_i v_{\eta, i}^2} \cdot \sqrt{\sum_i v_{\epsilon, i}^2} }.
\end{align*}
By definition, $\P[\eta > \epsilon] = \Phi(\beta)$ and we can therefore approximate $\omega$ by 
\begin{align*}
\hat{\omega} &= \Phi(\beta)\eta + \Phi(-\beta) \\
&= \Phi(\beta) \mu_\epsilon + \Phi(-\beta) \mu_\epsilon + \sum_i \big( \Phi(\beta) v_{\eta, i} + \Phi(-\beta) v_{\epsilon, i} \big) \delta_i.
\end{align*}
This is both similar and in some sense contrary to the Clark equation approach, in that the latter precisely computes the first two moments of the maximization of two normal RVs, whereas the canonical method approximates the distribution of the maximization of any two RVs using linear combinations of normal RVs. In their empirical comparison, Canon and Jeannot found that the canonical method tended to fall between Sculli's method and CorLCA in terms of both speed and approximation quality \cite{can16}. 


\subsection{Kamburowski's bounds}
\label{subsect.kamburowski}

When all costs are independent Gaussian RVs, Kamburowski was able to prove both upper and lower bounds on the first two moments\footnote{As noted in Section \ref{sect.bounds}, the upper bound on the variance technically remains a conjecture.} of the longest path distribution. Since normally distributed costs occur in many applications and the method is both cheap and somewhat similar to the approaches discussed previously in this section, we describe it in depth here.

The bounds are achieved by recursively computing four number sequences $\underline{m_i}$, $\overline{m_i}$, $\underline{s_i}$ and  $\overline{s_i}$ such that $\underline{m_i} \leq \mu_{L_i} \leq \overline{m_i}$ and $ \underline{s_i} \leq \sigma_{L_i} \leq \overline{s_i}$ for all $i = 1, \dots, n$. Clearly, by taking $\underline{m_1} = \overline{m_1} = \E[\pi_1]$ and $\underline{s_1} = \overline{s_1} = Var[\pi_1]$ we can achieve the desired bounds for $L_1$. (As ever, we can work backward instead in which case the analogous results hold for the index $n$.) Now we suppose that all of the upper and lower bounds have been computed for all of the parents of a given node $t_i$ and consider how we can construct  $\underline{m_i}$, $\overline{m_i}$, $\underline{s_i}$ and  $\overline{s_i}$. The variance bounds are relatively straightforward. The lower bound is given by
\begin{equation}
\underline{s_i^2} =\left\{
\begin{array}{@{}ll@{}}
\underline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}], \quad  \text{if $P_i = \{s_h\}$,} \\
0,  \quad \text{ otherwise},
\end{array}\right.
\label{eq.si_under}
\end{equation}
reflecting the fact that the variance, as computed by equation \eqref{eq.clark_max_sigma}, can be reduced to an arbitrary extent by a maximization (which needs to be performed for multiple parents). The (conjectured) upper bound is similarly a result of this fact,
\begin{align}
  \label{eq.si_over}
  \overline{s_i^2} = \max_{h \in P_i}\{ \overline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]\}.
\end{align}
The bounds on the expected value are somewhat more complex. First, define a function $h$ by
\begin{align*}
  h(\mu_i, \sigma_i, \mu_k, \sigma_k) = \mu_i \Phi(\overline{\beta}) + \mu_k \Phi(-\overline{\beta}) + \overline{\alpha} \phi(\overline{\beta}),
\end{align*}
where $\overline{\alpha} = \sigma_i^2 + \sigma_k^2$ and $\beta = (\mu_i - \mu_k)/ \overline{\alpha}$. Per equation \eqref{eq.clark_max_mu}, $h$ is the expected value of the maximization of two {\em independent} normally distributed RVs $X_i \sim N(\mu_i, \sigma_i^2)$ and $X_k \sim N(\mu_k, \sigma_k^2)$. Now, suppose that we have a set of (not necessarily independent) normally distributed RVs $X_1, X_2, \dots, X_r$, where each $X_i \sim N(\mu_i, \sigma_i^2)$ and $\sigma_1 \leq \sigma_2 \leq \dots \leq \sigma_r$. Define two functions $\underline{f}$ and $\overline{f}$ by the recursions,
\begin{align*}
  &\underline{f}(X_1) = \overline{f}(X_1) = \mu_1, \\
  &\underline{f}(X_1, X_2) = \overline{f}(X_1, X_2) = h(\mu_1, \sigma_1, \mu_2, \sigma_2), \\
  &\underline{f}(X_1, \dots, X_r) = h(\underline{f}(X_1, \dots, X_{r - 1}), 0, \mu_r, \sigma_r), \\
  &\overline{f}(X_1, \dots, X_r) = h(\overline{f}(X_1, \dots, X_{r - 1}), \sigma_{r - 1}, \mu_r, \sigma_r).
\end{align*}
Then, for all $i = 2, \dots, n$, if we define
\begin{align*}
  \underline{m_i} &= \underline{f}(\{ \underline{X_h} \}_{h \in S_i}),
\end{align*}
where
\begin{align*}
  \underline{X_h} &\sim N(\underline{m_h} + \E[\pi_{hi}] + \E[\pi_{i}], \; \underline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]),
\end{align*}
and
\begin{align*}
  \overline{m_i} &= \overline{f}(\{\overline{X_h}\}_{h \in S_i}),
\end{align*}
where
\begin{align*}
  \overline{X_h} \sim N(\overline{m_h} + \E[\pi_{hi}] + \E[\pi_{i}], \; \overline{s_h^2} + Var[\pi_{hi}] + Var[\pi_{i}]),
  \end{align*}
we have 
\begin{align*}
  \underline{m_i} \leq \mu_{L_i} \leq \overline{m_i}.
\end{align*}
(Here we are assuming that the sets $\{\underline{X_h}\}_{h \in S_i}$ and $\{\overline{X_h}\}_{h \in S_i}$ are ordered in such a way that the inequality constraints on the variances is satisfied.)

\subsubsection*{Questions for Neil}

I'm unsure about a few things here. 
\begin{enumerate}
\item Do the bounds on the expected value actually hold for dependent longest paths? The way that the result is presented in the original paper (Thm 1 on pg.~1052) would seem to suggest that the only necessary assumption is the independence of the costs themselves (which we do have) but then Thm 2 is presented immediately afterward which assumes all the $L_i$ are independent---basically am wondering if Thm 1 relies on Thm 2 or stands without it. Proofs are presented later in the paper but I don't fully understand these.
  \item Do the bounds actually require that all costs be normal (since max of two normals isn't actually normal anyway)? 
  \end{enumerate}


\section{Other approximation methods}
\label{sect.other_methods} 

% MC part is same as in previous chapter - where best to put it?

{\em Monte Carlo} methods have a long history in approximating the longest path distribution of PERT networks, dating back to at least the early 1960s \cite{van63}. The idea is to simulate the realization of all RVs and evaluate the longest path of the resulting deterministic graph. This is done repeatedly, giving a set of longest path instances whose empirical distribution function is guaranteed to converge to the true distribution by the Glivenko-Cantelli theorem \cite{can16}. Furthermore, analytical results allow us to quantify the approximation error for any given the number of realizations---and therefore the number of realizations needed to reach a desired accuracy. The major disadvantage is the cost, particularly when the number of realizations required is large, although modern architectures are well-suited to MC methods because of their parallelism so this problem may no longer be as acute as it once was. At any rate, in this chapter, we typically only use MC methods in order to obtain reference solutions.

If the graph is {\em series-parallel} then we can compute the exact distribution of the longest path length in polynomial-time through a series of reductions \cite{dod85,mar65}. If this isn't the case, similar methods have been proposed that give approximations to the distribution \cite{dod85,lud01}, however these tend to be less accurate than Monte Carlo-based methods and more expensive than the those based on the normality assumption \cite{can16}. 


\section{Updating makespan estimates}
\label{sect.updating}

% TODO: rewrite all this, no longer using this approach (see slides for viva presentation). "A big advantage of the correlation based approach is that we can quickly update the makespan/longest path estimate in response to realized data..."
% Mention emapse somewhere - e.g., we don't repeat the work of Canon, who did the best empirical comparison of different methods for computing the longest path distribution... Many of the methods discussed here were implemented in their emapse package... We chose to implement our own smaller-scale simulator for continuity with earlier work in this thesis...

Rather than considering how we can estimate the schedule length before it is executed, we focus here instead on the related problem of how schedule makespan estimates can be quickly updated {\em during} execution, perhaps in response to a large delay. The most straightforward way to do this of course is to simply replace all of the RVs that have been realized already with their realizations and recompute the makespan/longest path using whatever method we choose (Sculli, CorLCA, CorDyn, etc). However, this is typically an $O(n^2)$ operation and so can be considerable if the DAG is large.

Alternatively, we could compute the initial schedule length estimate by working backward through the DAG and estimating the remaining time until the end, disregarding the current task. In particular, we set $L_n = 0$ and recursively compute
\begin{align*}
  L_i = \max_{k \in S_i} \{ \pi_{ik} + \pi_k + L_k  \}
\end{align*}
for all other tasks, where the maximization is done using the Clark formulae, either with or without correlations (if using, for example, CorLCA, the correlation tree would need to represent the {\em reversed} DAG so that lowest common ancestors are actually deepest common descendants but this is fairly straightforward). Note that since the $L_i$ no longer include the current task, to estimate the total schedule makespan, we would just need to add $\pi_i$. By estimating the schedule length in this way, we can quickly update the final makespan estimate by adding the $L_i$ to the realization of the longest path up to and including $t_i$ (i.e., if $t_i$ finishes at time $f_i$, the new makespan estimate is $f_i + L_i$.)

Another possible method makes use of the following result, assuming that we first work forward through the DAG and compute estimates $L_i \sim N(\mu_i, \sigma_i)$ of the finish times of all tasks.
\begin{prop}
	Let $u$ be a normally distributed vector with mean $\bar{\mu}$ and covariance $\Sigma_u$, $u \sim N(\bar{\mu}, \Sigma_u)$, and suppose that $u = (v, w)$. Then 
	\begin{align*}
	(w \mid v) \sim N \big( \bar{w} + \Sigma_{wv}\Sigma_{vv}^{-1} (v - \bar{v}), \enspace  \Sigma_{ww} - \Sigma_{wv} \Sigma_{vv}^{-1} \Sigma_{vw} \big).
	\end{align*}
\end{prop}
Note that if all of the linear correlation coefficients $\rho_{uv}$ are known (which would be the case if we used CorLCA or Cordyn), we can use the definition $\rho_{uv} = \Sigma_{uv} / \sigma_u \sigma_v$ to find $\Sigma_{uv}$. For compactness of notation let $\rho_{in} = \rho_{ni}$ be the linear correlation coefficient between $L_i$ and $L_n$. Suppose that task $t_i$ has finished at time $\ell_i$. Then we can compute a new estimate $L_n'$ of the final makespan by applying the above result as follows,
\begin{align*}
L_n' &\sim N \bigg( \mu_{n} + \frac{\rho_{ni} \sigma_{n} \sigma_{i}}{\sigma_{i}^2} (\ell_i - \mu_{i}), \enspace \sigma_{n}^2 - \frac{\rho_{ni} \sigma_{n} \sigma_{i} \cdot \rho_{in} \sigma_{i} \sigma_{n}}{\sigma_{i}^2} \bigg) \nonumber\\
&\sim N \bigg(\mu_{n} + \frac{\rho_{ni} \sigma_{n}}{\sigma_{i}} (\ell_i - \mu_{i}), \enspace (1 - \rho_{ni}^2) \sigma_{n}^2 \bigg).
\end{align*} 

\subsubsection*{Questions for Neil}

\begin{enumerate}
\item The main question I have is, assuming that we use say CorLCA in the backward way to initially estimate the longest paths/finish times and estimate the correlation coefficients, is the update rule basically doing the exact same thing as just adding on the remaining time estimate---i.e., is $f_i + L_i$ the same as the distribution for $L_n'$ above?  
  \item Related to above, if they are different, is there any reason to assume the update rule is any better, given that they're both very cheap to compute and are based on the same set of correlation coefficients? 
  \end{enumerate}

% Suppose we are following a static schedule for which we have already computed an estimate of the makespan, how do we efficiently update the estimate dynamically at runtime, perhaps in response to a large delay? This is straightforward for deterministic static schedules since we can just recompute the critical path length of the schedule DAG using observed costs for those task that have already been processed and estimates for those that have not yet been processed. The same basic approach can also be used for stochastic schedules of course, but the picture is slightly more complex, as illustrated below.    

% For a given task DAG and target platform, suppose we have a static schedule that dictates what tasks each processor should execute and in what order, which they will do greedily (i.e., without artificial delays). Before runtime we work through the DAG and estimate the makespan distribution up to when each of the tasks has completed. These makespan estimates are modeled as normal RVs in accordance with the central limit theorem so that for each task $t_i$ we have an associated makespan estimate $F_i \sim N(\mu_i, \sigma_i^2)$, which is computed through  
% \begin{align}
% F_i = W_i + \max_{h \in P_i} \{ F_h + W_{hi} \}, \label{eq.finish_time}
% \end{align} 
% where $W_i$ and $W_{hi}$ here represent the relevant computation and communication costs (since the processors are fixed by the schedule). We make the standard assumption that all of the computation and communication costs are independent so the summations are done using the rule for normal RVs \eqref{eq.sum_moments} with the correlation coefficient assumed to be zero. We use Clark's equations \eqref{eq.clark_max_mu} and \eqref{eq.clark_max_sigma} to estimate the distribution of the maximization. The terms within are not generally independent because the parent tasks they represent may have common ancestors, so we can either ignore all correlations (which corresponds to Sculli's method) or estimate the correlation coefficients (as in CorLCA and Cordyn). 

% We are concerned with the situation at any given point during runtime when some tasks may have completed execution while others are still to be done. Let $f_h$ be the realization of the makespan estimate $F_h$ once task $t_h$ has actually been completed. In order to update the makespan estimate we need to move through the DAG and make use of the realizations of previous task makespans. Consider a generic task $t_i$ and suppose that some of its parent tasks have been processed but others have not. The most straightforward way to update $F_i$ is to simply use $f_h$ instead of $F_h$ in equation \eqref{eq.finish_time} for all those parents that have been realized. However, it would perhaps be better if we could use the realized parent makespans to update the makespan estimates $F_h$ for those parents that haven't yet finished. Let $f_m = \max_{h \in P_i} f_h$ be the greatest makespan of those parent tasks that have been processed. For all other parent tasks $t_h$ that have {\em not} yet been executed we want to estimate the remaining cost, given that it has not been completed but $t_m$ has been---i.e., we want to estimate $F_h' = F_h - f_m$ given that we know $f_h > f_m$. This can be done by applying the following result. 

% \begin{prop}
% 	Let $u$ be a normally distributed vector with mean $\bar{\mu}$ and covariance $\Sigma_u$, $u \sim N(\bar{\mu}, \Sigma_u)$, and suppose that $u = (v, w)$. Then 
% 	\begin{align*}
% 	(w \mid v) \sim N \big( \bar{w} + \Sigma_{wv}\Sigma_{vv}^{-1} (v - \bar{v}), \enspace  \Sigma_{ww} - \Sigma_{wv} \Sigma_{vv}^{-1} \Sigma_{vw} \big).
% 	\end{align*}
% \end{prop}
% Note that if all of the linear correlation coefficients $\rho_{uv}$ are known (which would be the case if we used CorLCA or Cordyn), we can use the definition $\rho_{uv} = \Sigma_{uv} / \sigma_u \sigma_v$ to find $\Sigma_{uv}$. For compactness of notation let $\rho_{hm} = \rho_{mh}$ be the linear correlation coefficient between $F_h$ and $F_m$. Then we have 
% \begin{align*}
% F_h' &\sim N \bigg( \mu_{h} + \frac{\rho_{hm} \sigma_{h} \sigma_{m}}{\sigma_{m}^2} (f_m - \mu_{m}), \enspace \sigma_{h}^2 - \frac{\rho_{hm} \sigma_{h} \sigma_{m} \cdot \rho_{mh} \sigma_{m} \sigma_{h}}{\sigma_{m}^2} \bigg) \nonumber\\
% &\sim N \bigg(\mu_{h} + \frac{\rho_{hm} \sigma_{h}}{\sigma_{m}} (f_m - \mu_{m}), \enspace (1 - \rho_{hm}^2) \sigma_{h}^2 \bigg).
% \end{align*} 
% The idea is that by using $F_h'$ rather than $F_h$ for those parent tasks that have not yet completed we can make greater use of the data available and should therefore obtain a superior estimate of the new makespan.  
% TODO: what if less than zero?


\section{Results}
\label{sect.results}

% mention emapse here?

We created a software framework to study the problem of approximating the makespan distribution of stochastic DAGs...

\subsection{Benchmarking}
\label{subsect.benchmarking}

We don't spend too much time on this since it was done much more thoroughly by Canon and Jeannot but we consider Sculli, CorLCA, possibly canonical and Cordyn for the Cholesky DAGs sets (i.e., we focus on a single example)...

\subsection{Update rule}
\label{subsect.results_update_rule}

Consider different permutations (fraction of tasks initially realized, distributions of the costs, etc) in a systematic manner and compare with MC estimates... 

\section{Conclusions}
\label{sect.conclusions}

What we really want to know: is there enough justification for considering the correlations in the context of a stochastic scheduling heuristic? 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Bibliography.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{myplain2-doi}
\bibliography{references,strings}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
